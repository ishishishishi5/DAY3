{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/ishimiwataru/Downloads/DNN_code_colab_lesson_3_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iters:0\n",
      "Loss:1.9037045303712357\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 1 0 1 0 1 1 0]\n",
      "62 + 24 = 0\n",
      "------------\n",
      "iters:100\n",
      "Loss:1.1849052859931832\n",
      "Pred:[1 1 1 0 0 0 0 1]\n",
      "True:[0 1 1 1 1 1 1 0]\n",
      "12 + 114 = 225\n",
      "------------\n",
      "iters:200\n",
      "Loss:1.218999997109689\n",
      "Pred:[0 0 0 0 0 0 1 0]\n",
      "True:[0 0 1 1 1 1 0 1]\n",
      "32 + 29 = 2\n",
      "------------\n",
      "iters:300\n",
      "Loss:1.0894105418382813\n",
      "Pred:[0 0 1 0 0 0 0 1]\n",
      "True:[1 0 1 1 1 0 1 0]\n",
      "122 + 64 = 33\n",
      "------------\n",
      "iters:400\n",
      "Loss:1.0543388526369382\n",
      "Pred:[1 1 1 1 1 0 1 1]\n",
      "True:[1 0 0 0 1 0 0 1]\n",
      "30 + 107 = 251\n",
      "------------\n",
      "iters:500\n",
      "Loss:0.955146177427269\n",
      "Pred:[1 1 1 1 1 0 1 1]\n",
      "True:[0 1 1 0 1 1 0 1]\n",
      "4 + 105 = 251\n",
      "------------\n",
      "iters:600\n",
      "Loss:0.9404020343773797\n",
      "Pred:[0 1 0 0 0 0 0 1]\n",
      "True:[0 1 0 1 1 0 0 0]\n",
      "14 + 74 = 65\n",
      "------------\n",
      "iters:700\n",
      "Loss:1.008921144942597\n",
      "Pred:[1 0 0 1 1 0 1 1]\n",
      "True:[1 0 1 0 1 1 1 0]\n",
      "79 + 95 = 155\n",
      "------------\n",
      "iters:800\n",
      "Loss:1.1856982659437878\n",
      "Pred:[1 1 1 1 1 1 1 1]\n",
      "True:[1 0 0 0 0 1 1 0]\n",
      "19 + 115 = 255\n",
      "------------\n",
      "iters:900\n",
      "Loss:0.9768675878268905\n",
      "Pred:[0 0 0 1 0 0 0 0]\n",
      "True:[1 1 1 0 0 0 0 0]\n",
      "102 + 122 = 16\n",
      "------------\n",
      "iters:1000\n",
      "Loss:0.8602656729737845\n",
      "Pred:[0 0 0 0 0 0 0 1]\n",
      "True:[0 1 1 0 1 0 0 1]\n",
      "37 + 68 = 1\n",
      "------------\n",
      "iters:1100\n",
      "Loss:0.8735310407499355\n",
      "Pred:[0 0 0 0 1 0 1 0]\n",
      "True:[0 0 1 0 1 0 1 1]\n",
      "33 + 10 = 10\n",
      "------------\n",
      "iters:1200\n",
      "Loss:0.8415852846250789\n",
      "Pred:[1 1 1 1 0 0 0 0]\n",
      "True:[1 0 0 1 0 0 0 0]\n",
      "64 + 80 = 240\n",
      "------------\n",
      "iters:1300\n",
      "Loss:0.9531197998476927\n",
      "Pred:[1 1 1 1 1 1 1 0]\n",
      "True:[1 0 1 0 1 0 0 0]\n",
      "126 + 42 = 254\n",
      "------------\n",
      "iters:1400\n",
      "Loss:1.0108825634839198\n",
      "Pred:[0 0 0 1 1 0 0 1]\n",
      "True:[1 0 1 0 0 0 0 1]\n",
      "69 + 92 = 25\n",
      "------------\n",
      "iters:1500\n",
      "Loss:1.0469072585515142\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 1 1 1 0 1 0 1]\n",
      "66 + 51 = 0\n",
      "------------\n",
      "iters:1600\n",
      "Loss:1.0311954796749638\n",
      "Pred:[0 0 1 0 1 0 0 1]\n",
      "True:[0 1 0 1 0 0 0 1]\n",
      "20 + 61 = 41\n",
      "------------\n",
      "iters:1700\n",
      "Loss:1.0285775296414328\n",
      "Pred:[1 1 1 1 1 1 1 1]\n",
      "True:[1 0 0 0 1 1 0 1]\n",
      "79 + 62 = 255\n",
      "------------\n",
      "iters:1800\n",
      "Loss:0.7550853140941722\n",
      "Pred:[0 1 1 0 0 0 1 0]\n",
      "True:[0 1 1 0 0 1 1 0]\n",
      "82 + 20 = 98\n",
      "------------\n",
      "iters:1900\n",
      "Loss:0.8854070321904743\n",
      "Pred:[0 1 1 1 1 1 0 1]\n",
      "True:[0 1 1 0 1 0 0 1]\n",
      "90 + 15 = 125\n",
      "------------\n",
      "iters:2000\n",
      "Loss:0.7523363454552977\n",
      "Pred:[1 0 0 1 1 1 1 1]\n",
      "True:[1 1 0 1 0 1 0 1]\n",
      "111 + 102 = 159\n",
      "------------\n",
      "iters:2100\n",
      "Loss:0.6651377608155564\n",
      "Pred:[1 1 1 1 0 0 1 1]\n",
      "True:[1 0 1 1 0 0 0 1]\n",
      "121 + 56 = 243\n",
      "------------\n",
      "iters:2200\n",
      "Loss:0.8482524956858709\n",
      "Pred:[1 1 1 0 0 1 1 0]\n",
      "True:[1 1 0 0 0 1 1 0]\n",
      "105 + 93 = 230\n",
      "------------\n",
      "iters:2300\n",
      "Loss:0.4086673980959358\n",
      "Pred:[0 1 0 1 1 0 1 0]\n",
      "True:[0 1 0 1 1 0 1 0]\n",
      "38 + 52 = 90\n",
      "------------\n",
      "iters:2400\n",
      "Loss:0.468721638365989\n",
      "Pred:[0 1 0 1 0 0 0 0]\n",
      "True:[0 1 1 1 0 0 0 0]\n",
      "80 + 32 = 80\n",
      "------------\n",
      "iters:2500\n",
      "Loss:0.3774048508494031\n",
      "Pred:[1 0 0 1 1 0 1 0]\n",
      "True:[1 0 0 1 1 0 1 0]\n",
      "84 + 70 = 154\n",
      "------------\n",
      "iters:2600\n",
      "Loss:0.5436687158495448\n",
      "Pred:[0 1 0 0 1 1 0 1]\n",
      "True:[0 1 0 0 1 1 0 1]\n",
      "25 + 52 = 77\n",
      "------------\n",
      "iters:2700\n",
      "Loss:0.489870632312963\n",
      "Pred:[1 1 0 0 1 1 0 0]\n",
      "True:[1 1 0 0 1 0 0 0]\n",
      "117 + 83 = 204\n",
      "------------\n",
      "iters:2800\n",
      "Loss:0.16839012959952449\n",
      "Pred:[0 0 0 1 0 0 0 1]\n",
      "True:[0 0 0 1 0 0 0 1]\n",
      "12 + 5 = 17\n",
      "------------\n",
      "iters:2900\n",
      "Loss:0.2527655988868056\n",
      "Pred:[0 1 1 1 1 0 0 0]\n",
      "True:[0 1 1 1 1 0 0 0]\n",
      "31 + 89 = 120\n",
      "------------\n",
      "iters:3000\n",
      "Loss:0.14495695882662823\n",
      "Pred:[0 1 0 1 0 1 0 0]\n",
      "True:[0 1 0 1 0 1 0 0]\n",
      "2 + 82 = 84\n",
      "------------\n",
      "iters:3100\n",
      "Loss:0.6944898966337545\n",
      "Pred:[1 1 1 0 1 0 0 1]\n",
      "True:[1 0 0 0 1 0 0 1]\n",
      "92 + 45 = 233\n",
      "------------\n",
      "iters:3200\n",
      "Loss:0.1327470758702454\n",
      "Pred:[0 1 1 1 1 1 0 1]\n",
      "True:[0 1 1 1 1 1 0 1]\n",
      "93 + 32 = 125\n",
      "------------\n",
      "iters:3300\n",
      "Loss:0.17865472397957022\n",
      "Pred:[1 0 0 1 0 1 0 0]\n",
      "True:[1 0 0 1 0 1 0 0]\n",
      "28 + 120 = 148\n",
      "------------\n",
      "iters:3400\n",
      "Loss:0.1509917774629118\n",
      "Pred:[1 0 0 1 0 0 1 1]\n",
      "True:[1 0 0 1 0 0 1 1]\n",
      "50 + 97 = 147\n",
      "------------\n",
      "iters:3500\n",
      "Loss:0.10594092345038661\n",
      "Pred:[0 1 1 1 0 1 0 0]\n",
      "True:[0 1 1 1 0 1 0 0]\n",
      "14 + 102 = 116\n",
      "------------\n",
      "iters:3600\n",
      "Loss:0.051370579241878316\n",
      "Pred:[1 0 0 0 1 1 0 0]\n",
      "True:[1 0 0 0 1 1 0 0]\n",
      "17 + 123 = 140\n",
      "------------\n",
      "iters:3700\n",
      "Loss:0.06775840138267208\n",
      "Pred:[1 0 1 1 0 1 1 0]\n",
      "True:[1 0 1 1 0 1 1 0]\n",
      "106 + 76 = 182\n",
      "------------\n",
      "iters:3800\n",
      "Loss:0.12069859206275307\n",
      "Pred:[1 1 1 0 1 1 1 0]\n",
      "True:[1 1 1 0 1 1 1 0]\n",
      "118 + 120 = 238\n",
      "------------\n",
      "iters:3900\n",
      "Loss:0.0420386795626079\n",
      "Pred:[1 0 1 1 0 0 1 0]\n",
      "True:[1 0 1 1 0 0 1 0]\n",
      "123 + 55 = 178\n",
      "------------\n",
      "iters:4000\n",
      "Loss:0.04797603242300456\n",
      "Pred:[0 1 0 1 1 1 0 0]\n",
      "True:[0 1 0 1 1 1 0 0]\n",
      "59 + 33 = 92\n",
      "------------\n",
      "iters:4100\n",
      "Loss:0.0448421291877419\n",
      "Pred:[1 0 0 1 1 0 1 1]\n",
      "True:[1 0 0 1 1 0 1 1]\n",
      "89 + 66 = 155\n",
      "------------\n",
      "iters:4200\n",
      "Loss:0.027522427813514723\n",
      "Pred:[1 0 0 1 0 1 1 0]\n",
      "True:[1 0 0 1 0 1 1 0]\n",
      "46 + 104 = 150\n",
      "------------\n",
      "iters:4300\n",
      "Loss:0.011466055918226397\n",
      "Pred:[1 0 1 1 0 1 0 0]\n",
      "True:[1 0 1 1 0 1 0 0]\n",
      "77 + 103 = 180\n",
      "------------\n",
      "iters:4400\n",
      "Loss:0.2287998671794657\n",
      "Pred:[1 1 0 1 1 1 1 1]\n",
      "True:[1 0 0 1 1 1 1 1]\n",
      "58 + 101 = 223\n",
      "------------\n",
      "iters:4500\n",
      "Loss:0.018576535687919882\n",
      "Pred:[0 1 1 1 0 1 0 0]\n",
      "True:[0 1 1 1 0 1 0 0]\n",
      "28 + 88 = 116\n",
      "------------\n",
      "iters:4600\n",
      "Loss:0.005931925370370946\n",
      "Pred:[0 0 0 1 0 1 1 0]\n",
      "True:[0 0 0 1 0 1 1 0]\n",
      "15 + 7 = 22\n",
      "------------\n",
      "iters:4700\n",
      "Loss:0.009506619729841749\n",
      "Pred:[0 0 1 0 1 0 1 1]\n",
      "True:[0 0 1 0 1 0 1 1]\n",
      "12 + 31 = 43\n",
      "------------\n",
      "iters:4800\n",
      "Loss:0.01608297620969845\n",
      "Pred:[1 0 1 0 1 0 1 0]\n",
      "True:[1 0 1 0 1 0 1 0]\n",
      "114 + 56 = 170\n",
      "------------\n",
      "iters:4900\n",
      "Loss:0.007159487571635682\n",
      "Pred:[0 1 0 1 1 1 0 0]\n",
      "True:[0 1 0 1 1 1 0 0]\n",
      "1 + 91 = 92\n",
      "------------\n",
      "iters:5000\n",
      "Loss:0.003872050573617882\n",
      "Pred:[0 1 1 1 1 0 0 0]\n",
      "True:[0 1 1 1 1 0 0 0]\n",
      "101 + 19 = 120\n",
      "------------\n",
      "iters:5100\n",
      "Loss:0.00855755839034861\n",
      "Pred:[0 0 1 0 1 1 0 1]\n",
      "True:[0 0 1 0 1 1 0 1]\n",
      "19 + 26 = 45\n",
      "------------\n",
      "iters:5200\n",
      "Loss:0.006577709084624053\n",
      "Pred:[0 0 1 0 0 1 0 1]\n",
      "True:[0 0 1 0 0 1 0 1]\n",
      "3 + 34 = 37\n",
      "------------\n",
      "iters:5300\n",
      "Loss:0.007462212339362231\n",
      "Pred:[0 1 1 1 0 0 1 1]\n",
      "True:[0 1 1 1 0 0 1 1]\n",
      "115 + 0 = 115\n",
      "------------\n",
      "iters:5400\n",
      "Loss:0.012584903905297812\n",
      "Pred:[0 1 0 0 1 0 0 0]\n",
      "True:[0 1 0 0 1 0 0 0]\n",
      "58 + 14 = 72\n",
      "------------\n",
      "iters:5500\n",
      "Loss:0.003722759716072831\n",
      "Pred:[1 0 0 1 0 0 0 0]\n",
      "True:[1 0 0 1 0 0 0 0]\n",
      "29 + 115 = 144\n",
      "------------\n",
      "iters:5600\n",
      "Loss:0.005763743132700495\n",
      "Pred:[0 1 1 1 1 0 0 1]\n",
      "True:[0 1 1 1 1 0 0 1]\n",
      "117 + 4 = 121\n",
      "------------\n",
      "iters:5700\n",
      "Loss:0.0077020329699748185\n",
      "Pred:[0 0 1 1 0 1 1 0]\n",
      "True:[0 0 1 1 0 1 1 0]\n",
      "38 + 16 = 54\n",
      "------------\n",
      "iters:5800\n",
      "Loss:0.007644915413262917\n",
      "Pred:[0 1 1 0 1 0 1 0]\n",
      "True:[0 1 1 0 1 0 1 0]\n",
      "98 + 8 = 106\n",
      "------------\n",
      "iters:5900\n",
      "Loss:0.002938141419210832\n",
      "Pred:[1 0 0 0 1 0 0 1]\n",
      "True:[1 0 0 0 1 0 0 1]\n",
      "112 + 25 = 137\n",
      "------------\n",
      "iters:6000\n",
      "Loss:0.005677473716887198\n",
      "Pred:[1 0 1 1 0 1 1 1]\n",
      "True:[1 0 1 1 0 1 1 1]\n",
      "125 + 58 = 183\n",
      "------------\n",
      "iters:6100\n",
      "Loss:0.00217724081292094\n",
      "Pred:[1 0 0 1 1 1 0 1]\n",
      "True:[1 0 0 1 1 1 0 1]\n",
      "48 + 109 = 157\n",
      "------------\n",
      "iters:6200\n",
      "Loss:0.002094020953795928\n",
      "Pred:[0 1 1 1 1 0 1 1]\n",
      "True:[0 1 1 1 1 0 1 1]\n",
      "122 + 1 = 123\n",
      "------------\n",
      "iters:6300\n",
      "Loss:0.0038795057900385364\n",
      "Pred:[1 1 0 1 1 0 0 1]\n",
      "True:[1 1 0 1 1 0 0 1]\n",
      "109 + 108 = 217\n",
      "------------\n",
      "iters:6400\n",
      "Loss:0.001270654784281384\n",
      "Pred:[0 0 1 1 1 0 0 1]\n",
      "True:[0 0 1 1 1 0 0 1]\n",
      "32 + 25 = 57\n",
      "------------\n",
      "iters:6500\n",
      "Loss:0.0031015038907789873\n",
      "Pred:[1 0 0 0 1 0 0 1]\n",
      "True:[1 0 0 0 1 0 0 1]\n",
      "73 + 64 = 137\n",
      "------------\n",
      "iters:6600\n",
      "Loss:0.0021664276657100846\n",
      "Pred:[0 1 1 0 0 1 0 1]\n",
      "True:[0 1 1 0 0 1 0 1]\n",
      "54 + 47 = 101\n",
      "------------\n",
      "iters:6700\n",
      "Loss:0.001334716027913985\n",
      "Pred:[0 1 1 0 0 0 0 0]\n",
      "True:[0 1 1 0 0 0 0 0]\n",
      "21 + 75 = 96\n",
      "------------\n",
      "iters:6800\n",
      "Loss:0.0013528032599118096\n",
      "Pred:[0 1 1 1 0 1 1 1]\n",
      "True:[0 1 1 1 0 1 1 1]\n",
      "52 + 67 = 119\n",
      "------------\n",
      "iters:6900\n",
      "Loss:0.0022847270717282313\n",
      "Pred:[0 1 0 1 0 0 1 1]\n",
      "True:[0 1 0 1 0 0 1 1]\n",
      "46 + 37 = 83\n",
      "------------\n",
      "iters:7000\n",
      "Loss:0.003556182859580408\n",
      "Pred:[0 1 1 0 0 0 1 1]\n",
      "True:[0 1 1 0 0 0 1 1]\n",
      "21 + 78 = 99\n",
      "------------\n",
      "iters:7100\n",
      "Loss:0.0013812070951241648\n",
      "Pred:[1 0 1 0 1 0 1 1]\n",
      "True:[1 0 1 0 1 0 1 1]\n",
      "80 + 91 = 171\n",
      "------------\n",
      "iters:7200\n",
      "Loss:0.003047180201309504\n",
      "Pred:[1 0 1 0 0 0 1 1]\n",
      "True:[1 0 1 0 0 0 1 1]\n",
      "63 + 100 = 163\n",
      "------------\n",
      "iters:7300\n",
      "Loss:0.0020040284650469013\n",
      "Pred:[0 1 0 1 0 0 1 1]\n",
      "True:[0 1 0 1 0 0 1 1]\n",
      "67 + 16 = 83\n",
      "------------\n",
      "iters:7400\n",
      "Loss:0.0005862928064709753\n",
      "Pred:[1 1 0 0 1 1 0 0]\n",
      "True:[1 1 0 0 1 1 0 0]\n",
      "101 + 103 = 204\n",
      "------------\n",
      "iters:7500\n",
      "Loss:0.0014885059700469627\n",
      "Pred:[1 0 0 0 1 0 1 1]\n",
      "True:[1 0 0 0 1 0 1 1]\n",
      "20 + 119 = 139\n",
      "------------\n",
      "iters:7600\n",
      "Loss:0.0010971653103162013\n",
      "Pred:[0 0 1 1 1 0 1 1]\n",
      "True:[0 0 1 1 1 0 1 1]\n",
      "24 + 35 = 59\n",
      "------------\n",
      "iters:7700\n",
      "Loss:0.0023739705090980827\n",
      "Pred:[1 0 1 1 0 0 1 1]\n",
      "True:[1 0 1 1 0 0 1 1]\n",
      "123 + 56 = 179\n",
      "------------\n",
      "iters:7800\n",
      "Loss:0.0031421979378943553\n",
      "Pred:[1 0 0 0 0 0 1 0]\n",
      "True:[1 0 0 0 0 0 1 0]\n",
      "114 + 16 = 130\n",
      "------------\n",
      "iters:7900\n",
      "Loss:0.0009031930315464082\n",
      "Pred:[0 1 1 1 1 1 0 1]\n",
      "True:[0 1 1 1 1 1 0 1]\n",
      "56 + 69 = 125\n",
      "------------\n",
      "iters:8000\n",
      "Loss:0.0012097269908249474\n",
      "Pred:[1 0 0 0 1 0 1 1]\n",
      "True:[1 0 0 0 1 0 1 1]\n",
      "20 + 119 = 139\n",
      "------------\n",
      "iters:8100\n",
      "Loss:0.0028447027789609445\n",
      "Pred:[0 1 0 1 0 0 0 0]\n",
      "True:[0 1 0 1 0 0 0 0]\n",
      "36 + 44 = 80\n",
      "------------\n",
      "iters:8200\n",
      "Loss:0.002852017129918139\n",
      "Pred:[1 1 0 0 0 1 0 0]\n",
      "True:[1 1 0 0 0 1 0 0]\n",
      "106 + 90 = 196\n",
      "------------\n",
      "iters:8300\n",
      "Loss:0.001480769129248086\n",
      "Pred:[0 1 0 1 0 0 1 1]\n",
      "True:[0 1 0 1 0 0 1 1]\n",
      "9 + 74 = 83\n",
      "------------\n",
      "iters:8400\n",
      "Loss:0.001020799812430649\n",
      "Pred:[0 0 1 1 0 1 0 1]\n",
      "True:[0 0 1 1 0 1 0 1]\n",
      "14 + 39 = 53\n",
      "------------\n",
      "iters:8500\n",
      "Loss:0.0005305918224753174\n",
      "Pred:[0 1 0 0 0 0 1 0]\n",
      "True:[0 1 0 0 0 0 1 0]\n",
      "17 + 49 = 66\n",
      "------------\n",
      "iters:8600\n",
      "Loss:0.0025660221503223564\n",
      "Pred:[0 1 1 0 1 1 0 0]\n",
      "True:[0 1 1 0 1 1 0 0]\n",
      "106 + 2 = 108\n",
      "------------\n",
      "iters:8700\n",
      "Loss:0.0011506405881193935\n",
      "Pred:[1 0 0 0 1 0 1 0]\n",
      "True:[1 0 0 0 1 0 1 0]\n",
      "127 + 11 = 138\n",
      "------------\n",
      "iters:8800\n",
      "Loss:0.0025213018917432757\n",
      "Pred:[1 0 1 1 1 0 1 0]\n",
      "True:[1 0 1 1 1 0 1 0]\n",
      "116 + 70 = 186\n",
      "------------\n",
      "iters:8900\n",
      "Loss:0.002203363009814194\n",
      "Pred:[0 1 1 1 0 1 1 0]\n",
      "True:[0 1 1 1 0 1 1 0]\n",
      "4 + 114 = 118\n",
      "------------\n",
      "iters:9000\n",
      "Loss:0.0009375642217406836\n",
      "Pred:[1 1 0 1 1 0 0 1]\n",
      "True:[1 1 0 1 1 0 0 1]\n",
      "98 + 119 = 217\n",
      "------------\n",
      "iters:9100\n",
      "Loss:0.000415518254415444\n",
      "Pred:[0 1 1 0 1 1 0 0]\n",
      "True:[0 1 1 0 1 1 0 0]\n",
      "81 + 27 = 108\n",
      "------------\n",
      "iters:9200\n",
      "Loss:0.0026015294586523626\n",
      "Pred:[0 1 1 0 1 0 1 0]\n",
      "True:[0 1 1 0 1 0 1 0]\n",
      "44 + 62 = 106\n",
      "------------\n",
      "iters:9300\n",
      "Loss:0.0023086842168506417\n",
      "Pred:[0 1 0 1 1 1 1 0]\n",
      "True:[0 1 0 1 1 1 1 0]\n",
      "50 + 44 = 94\n",
      "------------\n",
      "iters:9400\n",
      "Loss:0.0009131476211063325\n",
      "Pred:[1 0 0 0 0 1 1 1]\n",
      "True:[1 0 0 0 0 1 1 1]\n",
      "112 + 23 = 135\n",
      "------------\n",
      "iters:9500\n",
      "Loss:0.0006428135583949054\n",
      "Pred:[0 1 1 1 0 0 0 1]\n",
      "True:[0 1 1 1 0 0 0 1]\n",
      "56 + 57 = 113\n",
      "------------\n",
      "iters:9600\n",
      "Loss:0.0019868425318996176\n",
      "Pred:[1 1 1 0 0 1 0 0]\n",
      "True:[1 1 1 0 0 1 0 0]\n",
      "114 + 114 = 228\n",
      "------------\n",
      "iters:9700\n",
      "Loss:0.0004727646264659712\n",
      "Pred:[0 1 0 1 0 0 0 0]\n",
      "True:[0 1 0 1 0 0 0 0]\n",
      "31 + 49 = 80\n",
      "------------\n",
      "iters:9800\n",
      "Loss:0.0002725225406523347\n",
      "Pred:[0 1 1 1 1 0 0 0]\n",
      "True:[0 1 1 1 1 0 0 0]\n",
      "5 + 115 = 120\n",
      "------------\n",
      "iters:9900\n",
      "Loss:0.0017124421950879777\n",
      "Pred:[0 0 0 1 0 1 0 0]\n",
      "True:[0 0 0 1 0 1 0 0]\n",
      "2 + 18 = 20\n",
      "------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from common import functions\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# def d_tanh(x):\n",
    "\n",
    "\n",
    "\n",
    "# データを用意\n",
    "# 2進数の桁数\n",
    "binary_dim = 8\n",
    "# 最大値 + 1\n",
    "largest_number = pow(2, binary_dim)\n",
    "# largest_numberまで2進数を用意\n",
    "binary = np.unpackbits(np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n",
    "\n",
    "input_layer_size = 2\n",
    "hidden_layer_size = 16\n",
    "output_layer_size = 1\n",
    "\n",
    "weight_init_std = 1\n",
    "learning_rate = 0.1\n",
    "\n",
    "iters_num = 10000\n",
    "plot_interval = 100\n",
    "\n",
    "# ウェイト初期化 (バイアスは簡単のため省略)\n",
    "W_in = weight_init_std * np.random.randn(input_layer_size, hidden_layer_size)\n",
    "W_out = weight_init_std * np.random.randn(hidden_layer_size, output_layer_size)\n",
    "W = weight_init_std * np.random.randn(hidden_layer_size, hidden_layer_size)\n",
    "\n",
    "# Xavier\n",
    "\n",
    "\n",
    "# He\n",
    "\n",
    "\n",
    "\n",
    "# 勾配\n",
    "W_in_grad = np.zeros_like(W_in)\n",
    "W_out_grad = np.zeros_like(W_out)\n",
    "W_grad = np.zeros_like(W)\n",
    "\n",
    "u = np.zeros((hidden_layer_size, binary_dim + 1))\n",
    "z = np.zeros((hidden_layer_size, binary_dim + 1))\n",
    "y = np.zeros((output_layer_size, binary_dim))\n",
    "\n",
    "delta_out = np.zeros((output_layer_size, binary_dim))\n",
    "delta = np.zeros((hidden_layer_size, binary_dim + 1))\n",
    "\n",
    "all_losses = []\n",
    "\n",
    "for i in range(iters_num):\n",
    "    \n",
    "    # A, B初期化 (a + b = d)\n",
    "    a_int = np.random.randint(largest_number/2)\n",
    "    a_bin = binary[a_int] # binary encoding\n",
    "    b_int = np.random.randint(largest_number/2)\n",
    "    b_bin = binary[b_int] # binary encoding\n",
    "    \n",
    "    # 正解データ\n",
    "    d_int = a_int + b_int\n",
    "    d_bin = binary[d_int]\n",
    "    \n",
    "    # 出力バイナリ\n",
    "    out_bin = np.zeros_like(d_bin)\n",
    "    \n",
    "    # 時系列全体の誤差\n",
    "    all_loss = 0    \n",
    "    \n",
    "    # 時系列ループ\n",
    "    for t in range(binary_dim):\n",
    "        # 入力値\n",
    "        X = np.array([a_bin[ - t - 1], b_bin[ - t - 1]]).reshape(1, -1)\n",
    "        # 時刻tにおける正解データ\n",
    "        dd = np.array([d_bin[binary_dim - t - 1]])\n",
    "        \n",
    "        u[:,t+1] = np.dot(X, W_in) + np.dot(z[:,t].reshape(1, -1), W)\n",
    "        z[:,t+1] = functions.sigmoid(u[:,t+1])\n",
    "\n",
    "        y[:,t] = functions.sigmoid(np.dot(z[:,t+1].reshape(1, -1), W_out))\n",
    "\n",
    "\n",
    "        #誤差\n",
    "        loss = functions.mean_squared_error(dd, y[:,t])\n",
    "        \n",
    "        delta_out[:,t] = functions.d_mean_squared_error(dd, y[:,t]) * functions.d_sigmoid(y[:,t])        \n",
    "        \n",
    "        all_loss += loss\n",
    "\n",
    "        out_bin[binary_dim - t - 1] = np.round(y[:,t])\n",
    "    \n",
    "    \n",
    "    for t in range(binary_dim)[::-1]:\n",
    "        X = np.array([a_bin[-t-1],b_bin[-t-1]]).reshape(1, -1)        \n",
    "\n",
    "        delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_sigmoid(u[:,t+1])\n",
    "\n",
    "        # 勾配更新\n",
    "        W_out_grad += np.dot(z[:,t+1].reshape(-1,1), delta_out[:,t].reshape(-1,1))\n",
    "        W_grad += np.dot(z[:,t].reshape(-1,1), delta[:,t].reshape(1,-1))\n",
    "        W_in_grad += np.dot(X.T, delta[:,t].reshape(1,-1))\n",
    "    \n",
    "    # 勾配適用\n",
    "    W_in -= learning_rate * W_in_grad\n",
    "    W_out -= learning_rate * W_out_grad\n",
    "    W -= learning_rate * W_grad\n",
    "    \n",
    "    W_in_grad *= 0\n",
    "    W_out_grad *= 0\n",
    "    W_grad *= 0\n",
    "    \n",
    "\n",
    "    if(i % plot_interval == 0):\n",
    "        all_losses.append(all_loss)        \n",
    "        print(\"iters:\" + str(i))\n",
    "        print(\"Loss:\" + str(all_loss))\n",
    "        print(\"Pred:\" + str(out_bin))\n",
    "        print(\"True:\" + str(d_bin))\n",
    "        out_int = 0\n",
    "        for index,x in enumerate(reversed(out_bin)):\n",
    "            out_int += x * pow(2, index)\n",
    "        print(str(a_int) + \" + \" + str(b_int) + \" = \" + str(out_int))\n",
    "        print(\"------------\")\n",
    "\n",
    "lists = range(0, iters_num, plot_interval)\n",
    "plt.plot(lists, all_losses, label=\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "## [try] weight_init_stdやlearning_rate, hidden_layer_sizeを変更してみよう\n",
    "\n",
    "\n",
    "## [try] 重みの初期化方法を変更してみよう\n",
    "Xavier, He\n",
    "\n",
    "## [try] 中間層の活性化関数を変更してみよう\n",
    "ReLU(勾配爆発を確認しよう)<br>\n",
    "tanh(numpyにtanhが用意されている。導関数をd_tanhとして作成しよう)\n",
    "\n",
    "---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "leaaring_rate = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iters:0\n",
      "Loss:0.7754157238474925\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 0 1 0 1 0 0 0]\n",
      "27 + 13 = 0\n",
      "------------\n",
      "iters:100\n",
      "Loss:0.8185276835762273\n",
      "Pred:[1 1 1 1 1 1 1 1]\n",
      "True:[0 1 0 0 1 1 1 1]\n",
      "71 + 8 = 255\n",
      "------------\n",
      "iters:200\n",
      "Loss:1.0295822393451768\n",
      "Pred:[0 0 1 1 0 0 0 0]\n",
      "True:[1 0 0 0 1 0 0 1]\n",
      "113 + 24 = 48\n",
      "------------\n",
      "iters:300\n",
      "Loss:0.9366964914267366\n",
      "Pred:[0 1 1 1 1 1 1 1]\n",
      "True:[0 1 1 1 0 0 1 0]\n",
      "13 + 101 = 127\n",
      "------------\n",
      "iters:400\n",
      "Loss:1.026045725525255\n",
      "Pred:[1 0 0 1 1 0 1 0]\n",
      "True:[1 0 1 0 0 0 1 1]\n",
      "77 + 86 = 154\n",
      "------------\n",
      "iters:500\n",
      "Loss:0.9901741018699587\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[1 1 0 0 0 0 1 1]\n",
      "74 + 121 = 0\n",
      "------------\n",
      "iters:600\n",
      "Loss:0.987879613569417\n",
      "Pred:[1 0 1 0 0 0 0 0]\n",
      "True:[1 1 0 0 1 1 0 0]\n",
      "116 + 88 = 160\n",
      "------------\n",
      "iters:700\n",
      "Loss:0.8950396916516714\n",
      "Pred:[0 0 1 1 1 1 1 0]\n",
      "True:[0 0 1 0 0 0 0 0]\n",
      "31 + 1 = 62\n",
      "------------\n",
      "iters:800\n",
      "Loss:0.4419700514134652\n",
      "Pred:[1 1 1 0 1 1 0 0]\n",
      "True:[1 0 1 0 1 1 0 0]\n",
      "54 + 118 = 236\n",
      "------------\n",
      "iters:900\n",
      "Loss:0.6013645790242055\n",
      "Pred:[0 1 1 1 1 1 0 1]\n",
      "True:[0 1 1 0 0 0 0 1]\n",
      "74 + 23 = 125\n",
      "------------\n",
      "iters:1000\n",
      "Loss:0.2318155518594785\n",
      "Pred:[1 0 0 1 1 0 1 0]\n",
      "True:[1 0 0 1 1 0 1 0]\n",
      "56 + 98 = 154\n",
      "------------\n",
      "iters:1100\n",
      "Loss:0.07267556606234274\n",
      "Pred:[0 1 0 1 0 1 0 1]\n",
      "True:[0 1 0 1 0 1 0 1]\n",
      "60 + 25 = 85\n",
      "------------\n",
      "iters:1200\n",
      "Loss:0.07427495830723223\n",
      "Pred:[1 0 1 0 1 1 1 1]\n",
      "True:[1 0 1 0 1 1 1 1]\n",
      "59 + 116 = 175\n",
      "------------\n",
      "iters:1300\n",
      "Loss:0.08297221866023118\n",
      "Pred:[1 1 0 0 0 1 0 0]\n",
      "True:[1 1 0 0 0 1 0 0]\n",
      "83 + 113 = 196\n",
      "------------\n",
      "iters:1400\n",
      "Loss:0.05183909240363494\n",
      "Pred:[0 1 1 0 0 1 0 0]\n",
      "True:[0 1 1 0 0 1 0 0]\n",
      "53 + 47 = 100\n",
      "------------\n",
      "iters:1500\n",
      "Loss:0.004066862365408617\n",
      "Pred:[0 1 1 1 0 0 1 1]\n",
      "True:[0 1 1 1 0 0 1 1]\n",
      "115 + 0 = 115\n",
      "------------\n",
      "iters:1600\n",
      "Loss:0.013991524835109908\n",
      "Pred:[0 1 1 0 1 1 0 1]\n",
      "True:[0 1 1 0 1 1 0 1]\n",
      "94 + 15 = 109\n",
      "------------\n",
      "iters:1700\n",
      "Loss:0.0024522646411017516\n",
      "Pred:[0 1 1 0 0 0 1 1]\n",
      "True:[0 1 1 0 0 0 1 1]\n",
      "2 + 97 = 99\n",
      "------------\n",
      "iters:1800\n",
      "Loss:0.004478444137475791\n",
      "Pred:[1 0 0 0 0 0 1 0]\n",
      "True:[1 0 0 0 0 0 1 0]\n",
      "14 + 116 = 130\n",
      "------------\n",
      "iters:1900\n",
      "Loss:0.0018335063832558575\n",
      "Pred:[1 0 1 0 1 0 0 0]\n",
      "True:[1 0 1 0 1 0 0 0]\n",
      "126 + 42 = 168\n",
      "------------\n",
      "iters:2000\n",
      "Loss:0.001032776993710015\n",
      "Pred:[0 1 1 1 0 0 0 1]\n",
      "True:[0 1 1 1 0 0 0 1]\n",
      "83 + 30 = 113\n",
      "------------\n",
      "iters:2100\n",
      "Loss:0.0028274431979679847\n",
      "Pred:[0 0 1 1 0 0 0 0]\n",
      "True:[0 0 1 1 0 0 0 0]\n",
      "41 + 7 = 48\n",
      "------------\n",
      "iters:2200\n",
      "Loss:0.00032023451489004507\n",
      "Pred:[1 0 1 0 1 0 1 0]\n",
      "True:[1 0 1 0 1 0 1 0]\n",
      "117 + 53 = 170\n",
      "------------\n",
      "iters:2300\n",
      "Loss:0.0006756116013561299\n",
      "Pred:[0 1 0 1 1 0 1 1]\n",
      "True:[0 1 0 1 1 0 1 1]\n",
      "66 + 25 = 91\n",
      "------------\n",
      "iters:2400\n",
      "Loss:0.0005655585567158176\n",
      "Pred:[1 0 0 0 1 1 0 1]\n",
      "True:[1 0 0 0 1 1 0 1]\n",
      "55 + 86 = 141\n",
      "------------\n",
      "iters:2500\n",
      "Loss:0.0004564624349482077\n",
      "Pred:[1 0 0 0 0 0 1 1]\n",
      "True:[1 0 0 0 0 0 1 1]\n",
      "79 + 52 = 131\n",
      "------------\n",
      "iters:2600\n",
      "Loss:0.000754475206141031\n",
      "Pred:[1 0 0 0 0 1 0 1]\n",
      "True:[1 0 0 0 0 1 0 1]\n",
      "103 + 30 = 133\n",
      "------------\n",
      "iters:2700\n",
      "Loss:0.00019281904527978808\n",
      "Pred:[0 1 1 1 1 0 1 0]\n",
      "True:[0 1 1 1 1 0 1 0]\n",
      "71 + 51 = 122\n",
      "------------\n",
      "iters:2800\n",
      "Loss:0.000645746695827413\n",
      "Pred:[0 1 0 1 1 1 0 1]\n",
      "True:[0 1 0 1 1 1 0 1]\n",
      "78 + 15 = 93\n",
      "------------\n",
      "iters:2900\n",
      "Loss:0.000532034408695726\n",
      "Pred:[1 0 1 1 1 1 1 1]\n",
      "True:[1 0 1 1 1 1 1 1]\n",
      "80 + 111 = 191\n",
      "------------\n",
      "iters:3000\n",
      "Loss:8.287681149089923e-05\n",
      "Pred:[0 1 1 0 0 0 1 0]\n",
      "True:[0 1 1 0 0 0 1 0]\n",
      "77 + 21 = 98\n",
      "------------\n",
      "iters:3100\n",
      "Loss:0.00026608996847962625\n",
      "Pred:[1 1 0 1 1 0 1 1]\n",
      "True:[1 1 0 1 1 0 1 1]\n",
      "103 + 116 = 219\n",
      "------------\n",
      "iters:3200\n",
      "Loss:0.000446446841819977\n",
      "Pred:[0 0 1 1 0 1 1 1]\n",
      "True:[0 0 1 1 0 1 1 1]\n",
      "40 + 15 = 55\n",
      "------------\n",
      "iters:3300\n",
      "Loss:0.00030056570414053785\n",
      "Pred:[1 0 0 1 0 0 1 1]\n",
      "True:[1 0 0 1 0 0 1 1]\n",
      "41 + 106 = 147\n",
      "------------\n",
      "iters:3400\n",
      "Loss:0.0003770168234593258\n",
      "Pred:[0 1 0 1 0 0 0 0]\n",
      "True:[0 1 0 1 0 0 0 0]\n",
      "44 + 36 = 80\n",
      "------------\n",
      "iters:3500\n",
      "Loss:0.00038020803500924733\n",
      "Pred:[1 1 0 1 0 1 1 0]\n",
      "True:[1 1 0 1 0 1 1 0]\n",
      "108 + 106 = 214\n",
      "------------\n",
      "iters:3600\n",
      "Loss:0.00027614187312306325\n",
      "Pred:[0 0 1 1 1 0 1 1]\n",
      "True:[0 0 1 1 1 0 1 1]\n",
      "10 + 49 = 59\n",
      "------------\n",
      "iters:3700\n",
      "Loss:3.370394639188187e-05\n",
      "Pred:[1 0 0 0 1 0 1 0]\n",
      "True:[1 0 0 0 1 0 1 0]\n",
      "69 + 69 = 138\n",
      "------------\n",
      "iters:3800\n",
      "Loss:0.0002870624888595781\n",
      "Pred:[0 1 1 0 0 1 1 0]\n",
      "True:[0 1 1 0 0 1 1 0]\n",
      "86 + 16 = 102\n",
      "------------\n",
      "iters:3900\n",
      "Loss:0.0001714777706057941\n",
      "Pred:[1 0 0 0 1 1 0 0]\n",
      "True:[1 0 0 0 1 1 0 0]\n",
      "15 + 125 = 140\n",
      "------------\n",
      "iters:4000\n",
      "Loss:0.00017633054647697716\n",
      "Pred:[1 1 1 0 0 0 1 1]\n",
      "True:[1 1 1 0 0 0 1 1]\n",
      "107 + 120 = 227\n",
      "------------\n",
      "iters:4100\n",
      "Loss:0.0003079320979959763\n",
      "Pred:[0 1 1 0 0 1 0 0]\n",
      "True:[0 1 1 0 0 1 0 0]\n",
      "70 + 30 = 100\n",
      "------------\n",
      "iters:4200\n",
      "Loss:0.00010127192925818466\n",
      "Pred:[0 1 0 0 0 1 0 1]\n",
      "True:[0 1 0 0 0 1 0 1]\n",
      "21 + 48 = 69\n",
      "------------\n",
      "iters:4300\n",
      "Loss:0.0002600631764895316\n",
      "Pred:[1 1 0 0 1 0 0 1]\n",
      "True:[1 1 0 0 1 0 0 1]\n",
      "126 + 75 = 201\n",
      "------------\n",
      "iters:4400\n",
      "Loss:6.583851277903774e-05\n",
      "Pred:[1 0 0 0 0 1 0 0]\n",
      "True:[1 0 0 0 0 1 0 0]\n",
      "81 + 51 = 132\n",
      "------------\n",
      "iters:4500\n",
      "Loss:0.00018141592566166744\n",
      "Pred:[1 0 0 1 0 0 0 1]\n",
      "True:[1 0 0 1 0 0 0 1]\n",
      "27 + 118 = 145\n",
      "------------\n",
      "iters:4600\n",
      "Loss:0.00017576781039260682\n",
      "Pred:[1 1 0 0 1 1 0 0]\n",
      "True:[1 1 0 0 1 1 0 0]\n",
      "100 + 104 = 204\n",
      "------------\n",
      "iters:4700\n",
      "Loss:0.00016215117906533694\n",
      "Pred:[1 0 0 1 1 0 0 0]\n",
      "True:[1 0 0 1 1 0 0 0]\n",
      "120 + 32 = 152\n",
      "------------\n",
      "iters:4800\n",
      "Loss:0.00017775154454834733\n",
      "Pred:[1 0 1 0 0 1 0 0]\n",
      "True:[1 0 1 0 0 1 0 0]\n",
      "74 + 90 = 164\n",
      "------------\n",
      "iters:4900\n",
      "Loss:0.00014184899910379354\n",
      "Pred:[0 1 1 1 1 1 0 1]\n",
      "True:[0 1 1 1 1 1 0 1]\n",
      "114 + 11 = 125\n",
      "------------\n",
      "iters:5000\n",
      "Loss:0.00012277050613579378\n",
      "Pred:[0 1 0 1 1 1 0 1]\n",
      "True:[0 1 0 1 1 1 0 1]\n",
      "76 + 17 = 93\n",
      "------------\n",
      "iters:5100\n",
      "Loss:0.0001599124494990086\n",
      "Pred:[0 1 1 0 0 0 1 1]\n",
      "True:[0 1 1 0 0 0 1 1]\n",
      "28 + 71 = 99\n",
      "------------\n",
      "iters:5200\n",
      "Loss:0.00013495804914694253\n",
      "Pred:[0 1 1 0 0 0 0 1]\n",
      "True:[0 1 1 0 0 0 0 1]\n",
      "92 + 5 = 97\n",
      "------------\n",
      "iters:5300\n",
      "Loss:0.00015289881805767062\n",
      "Pred:[1 0 0 0 1 1 1 0]\n",
      "True:[1 0 0 0 1 1 1 0]\n",
      "24 + 118 = 142\n",
      "------------\n",
      "iters:5400\n",
      "Loss:6.587462019545092e-05\n",
      "Pred:[0 1 0 1 1 0 1 1]\n",
      "True:[0 1 0 1 1 0 1 1]\n",
      "43 + 48 = 91\n",
      "------------\n",
      "iters:5500\n",
      "Loss:0.00013142584533363562\n",
      "Pred:[0 1 1 0 0 0 0 1]\n",
      "True:[0 1 1 0 0 0 0 1]\n",
      "90 + 7 = 97\n",
      "------------\n",
      "iters:5600\n",
      "Loss:0.00011495461493982406\n",
      "Pred:[1 0 1 0 1 0 1 0]\n",
      "True:[1 0 1 0 1 0 1 0]\n",
      "58 + 112 = 170\n",
      "------------\n",
      "iters:5700\n",
      "Loss:3.286461871321835e-05\n",
      "Pred:[1 0 0 1 1 0 0 0]\n",
      "True:[1 0 0 1 1 0 0 0]\n",
      "99 + 53 = 152\n",
      "------------\n",
      "iters:5800\n",
      "Loss:3.331720751153672e-05\n",
      "Pred:[1 0 0 0 0 0 1 0]\n",
      "True:[1 0 0 0 0 0 1 0]\n",
      "59 + 71 = 130\n",
      "------------\n",
      "iters:5900\n",
      "Loss:9.144517870873419e-05\n",
      "Pred:[0 0 0 1 1 1 0 0]\n",
      "True:[0 0 0 1 1 1 0 0]\n",
      "6 + 22 = 28\n",
      "------------\n",
      "iters:6000\n",
      "Loss:5.36874255539536e-05\n",
      "Pred:[1 0 0 1 1 1 0 1]\n",
      "True:[1 0 0 1 1 1 0 1]\n",
      "117 + 40 = 157\n",
      "------------\n",
      "iters:6100\n",
      "Loss:0.0001001253630807061\n",
      "Pred:[0 1 0 1 1 0 1 0]\n",
      "True:[0 1 0 1 1 0 1 0]\n",
      "62 + 28 = 90\n",
      "------------\n",
      "iters:6200\n",
      "Loss:2.9081550275776034e-05\n",
      "Pred:[1 0 0 1 0 0 0 0]\n",
      "True:[1 0 0 1 0 0 0 0]\n",
      "43 + 101 = 144\n",
      "------------\n",
      "iters:6300\n",
      "Loss:1.865583447199959e-05\n",
      "Pred:[0 1 1 0 1 0 1 0]\n",
      "True:[0 1 1 0 1 0 1 0]\n",
      "87 + 19 = 106\n",
      "------------\n",
      "iters:6400\n",
      "Loss:8.493385413869793e-05\n",
      "Pred:[1 0 0 0 1 1 1 0]\n",
      "True:[1 0 0 0 1 1 1 0]\n",
      "84 + 58 = 142\n",
      "------------\n",
      "iters:6500\n",
      "Loss:4.699338417598063e-05\n",
      "Pred:[0 0 1 1 0 0 0 1]\n",
      "True:[0 0 1 1 0 0 0 1]\n",
      "1 + 48 = 49\n",
      "------------\n",
      "iters:6600\n",
      "Loss:2.7362277605549198e-05\n",
      "Pred:[0 1 1 1 0 0 1 0]\n",
      "True:[0 1 1 1 0 0 1 0]\n",
      "3 + 111 = 114\n",
      "------------\n",
      "iters:6700\n",
      "Loss:1.9259539589431537e-05\n",
      "Pred:[0 1 0 1 0 0 0 0]\n",
      "True:[0 1 0 1 0 0 0 0]\n",
      "31 + 49 = 80\n",
      "------------\n",
      "iters:6800\n",
      "Loss:4.105128464440443e-05\n",
      "Pred:[0 0 1 1 1 1 1 1]\n",
      "True:[0 0 1 1 1 1 1 1]\n",
      "31 + 32 = 63\n",
      "------------\n",
      "iters:6900\n",
      "Loss:8.563244978690334e-06\n",
      "Pred:[0 1 0 0 0 1 1 0]\n",
      "True:[0 1 0 0 0 1 1 0]\n",
      "65 + 5 = 70\n",
      "------------\n",
      "iters:7000\n",
      "Loss:4.278358293650722e-05\n",
      "Pred:[0 1 0 0 1 1 0 1]\n",
      "True:[0 1 0 0 1 1 0 1]\n",
      "57 + 20 = 77\n",
      "------------\n",
      "iters:7100\n",
      "Loss:1.268828206069355e-05\n",
      "Pred:[0 1 1 0 1 1 1 0]\n",
      "True:[0 1 1 0 1 1 1 0]\n",
      "91 + 19 = 110\n",
      "------------\n",
      "iters:7200\n",
      "Loss:3.6488995162121695e-05\n",
      "Pred:[1 0 1 1 0 1 1 1]\n",
      "True:[1 0 1 1 0 1 1 1]\n",
      "91 + 92 = 183\n",
      "------------\n",
      "iters:7300\n",
      "Loss:3.742085364700877e-05\n",
      "Pred:[1 0 0 1 1 0 1 1]\n",
      "True:[1 0 0 1 1 0 1 1]\n",
      "99 + 56 = 155\n",
      "------------\n",
      "iters:7400\n",
      "Loss:8.31805390849586e-06\n",
      "Pred:[1 0 1 1 1 0 1 0]\n",
      "True:[1 0 1 1 1 0 1 0]\n",
      "77 + 109 = 186\n",
      "------------\n",
      "iters:7500\n",
      "Loss:3.556324988883826e-05\n",
      "Pred:[0 1 1 0 1 0 1 1]\n",
      "True:[0 1 1 0 1 0 1 1]\n",
      "93 + 14 = 107\n",
      "------------\n",
      "iters:7600\n",
      "Loss:5.4077077462582766e-05\n",
      "Pred:[0 1 0 0 1 0 0 0]\n",
      "True:[0 1 0 0 1 0 0 0]\n",
      "72 + 0 = 72\n",
      "------------\n",
      "iters:7700\n",
      "Loss:1.3485207910302443e-05\n",
      "Pred:[1 0 1 1 0 1 0 0]\n",
      "True:[1 0 1 1 0 1 0 0]\n",
      "75 + 105 = 180\n",
      "------------\n",
      "iters:7800\n",
      "Loss:5.0144492664964305e-05\n",
      "Pred:[0 1 0 1 1 0 0 1]\n",
      "True:[0 1 0 1 1 0 0 1]\n",
      "88 + 1 = 89\n",
      "------------\n",
      "iters:7900\n",
      "Loss:5.280094244159435e-05\n",
      "Pred:[0 1 1 0 1 1 0 0]\n",
      "True:[0 1 1 0 1 1 0 0]\n",
      "54 + 54 = 108\n",
      "------------\n",
      "iters:8000\n",
      "Loss:5.406994322676902e-05\n",
      "Pred:[1 0 0 1 0 1 1 1]\n",
      "True:[1 0 0 1 0 1 1 1]\n",
      "26 + 125 = 151\n",
      "------------\n",
      "iters:8100\n",
      "Loss:3.512218691713969e-05\n",
      "Pred:[1 0 0 1 0 0 0 1]\n",
      "True:[1 0 0 1 0 0 0 1]\n",
      "63 + 82 = 145\n",
      "------------\n",
      "iters:8200\n",
      "Loss:5.372762977285043e-06\n",
      "Pred:[0 0 1 0 0 0 1 0]\n",
      "True:[0 0 1 0 0 0 1 0]\n",
      "33 + 1 = 34\n",
      "------------\n",
      "iters:8300\n",
      "Loss:1.3115480106144655e-05\n",
      "Pred:[1 0 0 1 0 1 0 0]\n",
      "True:[1 0 0 1 0 1 0 0]\n",
      "103 + 45 = 148\n",
      "------------\n",
      "iters:8400\n",
      "Loss:5.6236316383028854e-05\n",
      "Pred:[0 1 1 1 0 0 1 1]\n",
      "True:[0 1 1 1 0 0 1 1]\n",
      "60 + 55 = 115\n",
      "------------\n",
      "iters:8500\n",
      "Loss:3.2015975223444884e-05\n",
      "Pred:[1 0 0 0 1 0 0 1]\n",
      "True:[1 0 0 0 1 0 0 1]\n",
      "123 + 14 = 137\n",
      "------------\n",
      "iters:8600\n",
      "Loss:5.700403128128979e-06\n",
      "Pred:[0 1 1 1 1 1 1 0]\n",
      "True:[0 1 1 1 1 1 1 0]\n",
      "21 + 105 = 126\n",
      "------------\n",
      "iters:8700\n",
      "Loss:3.74564267739606e-05\n",
      "Pred:[1 0 1 0 0 1 0 1]\n",
      "True:[1 0 1 0 0 1 0 1]\n",
      "96 + 69 = 165\n",
      "------------\n",
      "iters:8800\n",
      "Loss:1.6686302974267e-05\n",
      "Pred:[1 0 0 1 1 1 0 0]\n",
      "True:[1 0 0 1 1 1 0 0]\n",
      "49 + 107 = 156\n",
      "------------\n",
      "iters:8900\n",
      "Loss:4.3154446976502015e-05\n",
      "Pred:[0 1 0 0 0 0 1 0]\n",
      "True:[0 1 0 0 0 0 1 0]\n",
      "60 + 6 = 66\n",
      "------------\n",
      "iters:9000\n",
      "Loss:2.118400620154884e-05\n",
      "Pred:[1 0 1 1 0 0 1 1]\n",
      "True:[1 0 1 1 0 0 1 1]\n",
      "75 + 104 = 179\n",
      "------------\n",
      "iters:9100\n",
      "Loss:1.5001954284427173e-05\n",
      "Pred:[0 0 1 0 0 1 0 0]\n",
      "True:[0 0 1 0 0 1 0 0]\n",
      "21 + 15 = 36\n",
      "------------\n",
      "iters:9200\n",
      "Loss:2.3212050279948222e-05\n",
      "Pred:[0 1 1 0 1 0 0 1]\n",
      "True:[0 1 1 0 1 0 0 1]\n",
      "9 + 96 = 105\n",
      "------------\n",
      "iters:9300\n",
      "Loss:2.245753628074595e-05\n",
      "Pred:[1 0 1 1 1 1 1 1]\n",
      "True:[1 0 1 1 1 1 1 1]\n",
      "65 + 126 = 191\n",
      "------------\n",
      "iters:9400\n",
      "Loss:4.733982807057269e-06\n",
      "Pred:[0 0 1 1 0 1 1 0]\n",
      "True:[0 0 1 1 0 1 1 0]\n",
      "45 + 9 = 54\n",
      "------------\n",
      "iters:9500\n",
      "Loss:1.6741078475870666e-05\n",
      "Pred:[0 1 0 0 1 0 0 0]\n",
      "True:[0 1 0 0 1 0 0 0]\n",
      "15 + 57 = 72\n",
      "------------\n",
      "iters:9600\n",
      "Loss:4.5478201199278e-06\n",
      "Pred:[0 1 1 1 1 1 1 0]\n",
      "True:[0 1 1 1 1 1 1 0]\n",
      "69 + 57 = 126\n",
      "------------\n",
      "iters:9700\n",
      "Loss:3.225883770090945e-05\n",
      "Pred:[0 0 0 0 1 1 0 0]\n",
      "True:[0 0 0 0 1 1 0 0]\n",
      "0 + 12 = 12\n",
      "------------\n",
      "iters:9800\n",
      "Loss:2.9700545170614602e-05\n",
      "Pred:[0 1 1 1 0 1 0 1]\n",
      "True:[0 1 1 1 0 1 0 1]\n",
      "98 + 19 = 117\n",
      "------------\n",
      "iters:9900\n",
      "Loss:3.216727525688178e-05\n",
      "Pred:[0 1 1 1 0 0 0 0]\n",
      "True:[0 1 1 1 0 0 0 0]\n",
      "14 + 98 = 112\n",
      "------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from common import functions\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# def d_tanh(x):\n",
    "\n",
    "\n",
    "\n",
    "# データを用意\n",
    "# 2進数の桁数\n",
    "binary_dim = 8\n",
    "# 最大値 + 1\n",
    "largest_number = pow(2, binary_dim)\n",
    "# largest_numberまで2進数を用意\n",
    "binary = np.unpackbits(np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n",
    "\n",
    "input_layer_size = 2\n",
    "hidden_layer_size = 16\n",
    "output_layer_size = 1\n",
    "\n",
    "weight_init_std = 1\n",
    "learning_rate = 0.5\n",
    "\n",
    "iters_num = 10000\n",
    "plot_interval = 100\n",
    "\n",
    "# ウェイト初期化 (バイアスは簡単のため省略)\n",
    "W_in = weight_init_std * np.random.randn(input_layer_size, hidden_layer_size)\n",
    "W_out = weight_init_std * np.random.randn(hidden_layer_size, output_layer_size)\n",
    "W = weight_init_std * np.random.randn(hidden_layer_size, hidden_layer_size)\n",
    "\n",
    "# Xavier\n",
    "\n",
    "\n",
    "# He\n",
    "\n",
    "\n",
    "\n",
    "# 勾配\n",
    "W_in_grad = np.zeros_like(W_in)\n",
    "W_out_grad = np.zeros_like(W_out)\n",
    "W_grad = np.zeros_like(W)\n",
    "\n",
    "u = np.zeros((hidden_layer_size, binary_dim + 1))\n",
    "z = np.zeros((hidden_layer_size, binary_dim + 1))\n",
    "y = np.zeros((output_layer_size, binary_dim))\n",
    "\n",
    "delta_out = np.zeros((output_layer_size, binary_dim))\n",
    "delta = np.zeros((hidden_layer_size, binary_dim + 1))\n",
    "\n",
    "all_losses = []\n",
    "\n",
    "for i in range(iters_num):\n",
    "    \n",
    "    # A, B初期化 (a + b = d)\n",
    "    a_int = np.random.randint(largest_number/2)\n",
    "    a_bin = binary[a_int] # binary encoding\n",
    "    b_int = np.random.randint(largest_number/2)\n",
    "    b_bin = binary[b_int] # binary encoding\n",
    "    \n",
    "    # 正解データ\n",
    "    d_int = a_int + b_int\n",
    "    d_bin = binary[d_int]\n",
    "    \n",
    "    # 出力バイナリ\n",
    "    out_bin = np.zeros_like(d_bin)\n",
    "    \n",
    "    # 時系列全体の誤差\n",
    "    all_loss = 0    \n",
    "    \n",
    "    # 時系列ループ\n",
    "    for t in range(binary_dim):\n",
    "        # 入力値\n",
    "        X = np.array([a_bin[ - t - 1], b_bin[ - t - 1]]).reshape(1, -1)\n",
    "        # 時刻tにおける正解データ\n",
    "        dd = np.array([d_bin[binary_dim - t - 1]])\n",
    "        \n",
    "        u[:,t+1] = np.dot(X, W_in) + np.dot(z[:,t].reshape(1, -1), W)\n",
    "        z[:,t+1] = functions.sigmoid(u[:,t+1])\n",
    "\n",
    "        y[:,t] = functions.sigmoid(np.dot(z[:,t+1].reshape(1, -1), W_out))\n",
    "\n",
    "\n",
    "        #誤差\n",
    "        loss = functions.mean_squared_error(dd, y[:,t])\n",
    "        \n",
    "        delta_out[:,t] = functions.d_mean_squared_error(dd, y[:,t]) * functions.d_sigmoid(y[:,t])        \n",
    "        \n",
    "        all_loss += loss\n",
    "\n",
    "        out_bin[binary_dim - t - 1] = np.round(y[:,t])\n",
    "    \n",
    "    \n",
    "    for t in range(binary_dim)[::-1]:\n",
    "        X = np.array([a_bin[-t-1],b_bin[-t-1]]).reshape(1, -1)        \n",
    "\n",
    "        delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_sigmoid(u[:,t+1])\n",
    "\n",
    "        # 勾配更新\n",
    "        W_out_grad += np.dot(z[:,t+1].reshape(-1,1), delta_out[:,t].reshape(-1,1))\n",
    "        W_grad += np.dot(z[:,t].reshape(-1,1), delta[:,t].reshape(1,-1))\n",
    "        W_in_grad += np.dot(X.T, delta[:,t].reshape(1,-1))\n",
    "    \n",
    "    # 勾配適用\n",
    "    W_in -= learning_rate * W_in_grad\n",
    "    W_out -= learning_rate * W_out_grad\n",
    "    W -= learning_rate * W_grad\n",
    "    \n",
    "    W_in_grad *= 0\n",
    "    W_out_grad *= 0\n",
    "    W_grad *= 0\n",
    "    \n",
    "\n",
    "    if(i % plot_interval == 0):\n",
    "        all_losses.append(all_loss)        \n",
    "        print(\"iters:\" + str(i))\n",
    "        print(\"Loss:\" + str(all_loss))\n",
    "        print(\"Pred:\" + str(out_bin))\n",
    "        print(\"True:\" + str(d_bin))\n",
    "        out_int = 0\n",
    "        for index,x in enumerate(reversed(out_bin)):\n",
    "            out_int += x * pow(2, index)\n",
    "        print(str(a_int) + \" + \" + str(b_int) + \" = \" + str(out_int))\n",
    "        print(\"------------\")\n",
    "\n",
    "lists = range(0, iters_num, plot_interval)\n",
    "plt.plot(lists, all_losses, label=\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iters:0\n",
      "Loss:1.462670753898649\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[1 1 0 0 1 1 0 1]\n",
      "94 + 111 = 0\n",
      "------------\n",
      "iters:100\n",
      "Loss:1.1164532161013045\n",
      "Pred:[1 1 1 1 1 1 0 0]\n",
      "True:[1 0 0 0 0 0 1 0]\n",
      "21 + 109 = 252\n",
      "------------\n",
      "iters:200\n",
      "Loss:0.9432864806324492\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[1 0 1 1 0 0 0 0]\n",
      "61 + 115 = 0\n",
      "------------\n",
      "iters:300\n",
      "Loss:0.9788274628080318\n",
      "Pred:[0 0 0 0 0 0 1 1]\n",
      "True:[0 1 0 1 0 0 1 0]\n",
      "65 + 17 = 3\n",
      "------------\n",
      "iters:400\n",
      "Loss:0.9686145840842362\n",
      "Pred:[1 1 1 1 1 1 1 1]\n",
      "True:[0 1 0 0 1 1 0 1]\n",
      "44 + 33 = 255\n",
      "------------\n",
      "iters:500\n",
      "Loss:0.8021398385829323\n",
      "Pred:[1 1 1 1 1 1 1 1]\n",
      "True:[0 0 1 1 1 1 0 1]\n",
      "33 + 28 = 255\n",
      "------------\n",
      "iters:600\n",
      "Loss:1.103346232864149\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[1 1 0 0 0 1 1 1]\n",
      "95 + 104 = 0\n",
      "------------\n",
      "iters:700\n",
      "Loss:1.0679900466809187\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[1 1 0 1 1 1 0 1]\n",
      "97 + 124 = 0\n",
      "------------\n",
      "iters:800\n",
      "Loss:0.9601941165693116\n",
      "Pred:[1 0 1 1 1 1 1 1]\n",
      "True:[0 1 1 1 1 0 0 1]\n",
      "26 + 95 = 191\n",
      "------------\n",
      "iters:900\n",
      "Loss:1.0112700573986324\n",
      "Pred:[1 1 1 1 1 1 0 0]\n",
      "True:[1 1 0 0 0 0 0 0]\n",
      "126 + 66 = 252\n",
      "------------\n",
      "iters:1000\n",
      "Loss:0.944165544814634\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 1 1 1 0 0 1 0]\n",
      "106 + 8 = 0\n",
      "------------\n",
      "iters:1100\n",
      "Loss:1.105600717223951\n",
      "Pred:[1 1 1 1 1 0 1 0]\n",
      "True:[1 0 0 1 0 0 0 1]\n",
      "20 + 125 = 250\n",
      "------------\n",
      "iters:1200\n",
      "Loss:0.8381113280536413\n",
      "Pred:[1 1 0 1 1 1 1 0]\n",
      "True:[1 0 0 1 1 1 0 0]\n",
      "86 + 70 = 222\n",
      "------------\n",
      "iters:1300\n",
      "Loss:0.8901786170483874\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[0 1 0 1 0 0 1 1]\n",
      "67 + 16 = 0\n",
      "------------\n",
      "iters:1400\n",
      "Loss:0.7915998181056965\n",
      "Pred:[1 1 0 0 0 1 1 1]\n",
      "True:[1 1 0 0 0 0 1 1]\n",
      "96 + 99 = 199\n",
      "------------\n",
      "iters:1500\n",
      "Loss:0.8934308174060478\n",
      "Pred:[1 0 0 0 1 0 0 0]\n",
      "True:[1 0 0 1 1 1 0 0]\n",
      "70 + 86 = 136\n",
      "------------\n",
      "iters:1600\n",
      "Loss:0.9398821472299195\n",
      "Pred:[0 0 0 0 0 1 0 1]\n",
      "True:[0 1 1 1 0 1 1 1]\n",
      "114 + 5 = 5\n",
      "------------\n",
      "iters:1700\n",
      "Loss:0.9258795135638715\n",
      "Pred:[0 1 0 0 0 1 0 0]\n",
      "True:[0 1 1 1 1 0 0 0]\n",
      "102 + 18 = 68\n",
      "------------\n",
      "iters:1800\n",
      "Loss:0.9846789709598022\n",
      "Pred:[1 0 0 1 0 0 0 0]\n",
      "True:[1 1 1 0 1 0 0 1]\n",
      "125 + 108 = 144\n",
      "------------\n",
      "iters:1900\n",
      "Loss:0.9256484095737841\n",
      "Pred:[1 0 0 0 0 0 0 0]\n",
      "True:[1 0 1 1 0 1 0 0]\n",
      "65 + 115 = 128\n",
      "------------\n",
      "iters:2000\n",
      "Loss:0.8676787937917404\n",
      "Pred:[0 1 1 1 1 1 0 1]\n",
      "True:[0 1 0 1 1 1 1 0]\n",
      "71 + 23 = 125\n",
      "------------\n",
      "iters:2100\n",
      "Loss:0.8470568164933481\n",
      "Pred:[0 1 0 1 1 1 1 1]\n",
      "True:[0 1 0 1 1 1 1 1]\n",
      "66 + 29 = 95\n",
      "------------\n",
      "iters:2200\n",
      "Loss:0.999019406575009\n",
      "Pred:[0 1 1 1 1 0 1 1]\n",
      "True:[1 0 1 0 1 0 1 1]\n",
      "121 + 50 = 123\n",
      "------------\n",
      "iters:2300\n",
      "Loss:0.81918525381826\n",
      "Pred:[1 0 1 1 1 0 1 1]\n",
      "True:[1 0 1 1 1 0 1 1]\n",
      "121 + 66 = 187\n",
      "------------\n",
      "iters:2400\n",
      "Loss:1.2921170122124395\n",
      "Pred:[0 1 0 1 1 1 1 1]\n",
      "True:[0 1 1 0 0 0 0 0]\n",
      "75 + 21 = 95\n",
      "------------\n",
      "iters:2500\n",
      "Loss:0.9576020511642721\n",
      "Pred:[0 1 1 1 1 1 1 1]\n",
      "True:[1 0 0 1 1 0 1 1]\n",
      "38 + 117 = 127\n",
      "------------\n",
      "iters:2600\n",
      "Loss:1.1021640216901853\n",
      "Pred:[0 1 1 1 0 1 1 1]\n",
      "True:[1 0 0 0 0 1 1 1]\n",
      "109 + 26 = 119\n",
      "------------\n",
      "iters:2700\n",
      "Loss:0.9728450499763248\n",
      "Pred:[1 0 0 1 1 0 1 1]\n",
      "True:[1 0 1 0 0 0 0 1]\n",
      "84 + 77 = 155\n",
      "------------\n",
      "iters:2800\n",
      "Loss:1.2058890008360101\n",
      "Pred:[1 0 1 1 1 1 1 1]\n",
      "True:[1 1 0 0 0 0 0 1]\n",
      "84 + 109 = 191\n",
      "------------\n",
      "iters:2900\n",
      "Loss:0.8890835346983763\n",
      "Pred:[1 1 0 0 1 1 1 1]\n",
      "True:[1 0 1 0 0 1 1 1]\n",
      "54 + 113 = 207\n",
      "------------\n",
      "iters:3000\n",
      "Loss:0.46680477260729214\n",
      "Pred:[1 0 1 1 1 1 1 0]\n",
      "True:[1 0 1 1 1 1 1 0]\n",
      "118 + 72 = 190\n",
      "------------\n",
      "iters:3100\n",
      "Loss:0.7120006365947745\n",
      "Pred:[1 0 1 1 0 1 1 1]\n",
      "True:[1 0 1 0 0 1 1 1]\n",
      "79 + 88 = 183\n",
      "------------\n",
      "iters:3200\n",
      "Loss:0.44411724270582936\n",
      "Pred:[1 1 1 1 1 1 1 1]\n",
      "True:[1 0 1 1 0 1 1 1]\n",
      "104 + 79 = 255\n",
      "------------\n",
      "iters:3300\n",
      "Loss:0.5961337336606031\n",
      "Pred:[1 0 0 1 1 0 0 0]\n",
      "True:[1 0 0 1 1 0 0 0]\n",
      "54 + 98 = 152\n",
      "------------\n",
      "iters:3400\n",
      "Loss:0.15843227364439907\n",
      "Pred:[0 0 0 1 1 0 1 0]\n",
      "True:[0 0 0 1 1 0 1 0]\n",
      "8 + 18 = 26\n",
      "------------\n",
      "iters:3500\n",
      "Loss:0.5843033995148529\n",
      "Pred:[0 0 1 1 1 1 0 0]\n",
      "True:[0 0 1 0 0 0 0 0]\n",
      "12 + 20 = 60\n",
      "------------\n",
      "iters:3600\n",
      "Loss:0.9469208895483442\n",
      "Pred:[0 1 1 1 1 0 0 1]\n",
      "True:[0 1 0 0 0 0 0 1]\n",
      "5 + 60 = 121\n",
      "------------\n",
      "iters:3700\n",
      "Loss:0.8196936657672564\n",
      "Pred:[0 1 0 0 0 0 0 0]\n",
      "True:[0 1 0 0 0 1 0 0]\n",
      "45 + 23 = 64\n",
      "------------\n",
      "iters:3800\n",
      "Loss:0.3274961986924135\n",
      "Pred:[1 0 1 1 1 1 1 1]\n",
      "True:[1 0 1 1 1 1 1 1]\n",
      "109 + 82 = 191\n",
      "------------\n",
      "iters:3900\n",
      "Loss:0.38401504316753954\n",
      "Pred:[0 1 0 1 1 1 1 1]\n",
      "True:[0 1 0 1 1 1 1 1]\n",
      "63 + 32 = 95\n",
      "------------\n",
      "iters:4000\n",
      "Loss:0.6056828836020839\n",
      "Pred:[0 1 1 1 0 1 0 1]\n",
      "True:[0 1 0 0 0 1 0 1]\n",
      "40 + 29 = 117\n",
      "------------\n",
      "iters:4100\n",
      "Loss:0.6951574681786754\n",
      "Pred:[1 0 0 0 0 0 1 0]\n",
      "True:[1 0 0 1 0 0 1 0]\n",
      "62 + 84 = 130\n",
      "------------\n",
      "iters:4200\n",
      "Loss:0.5890617690259479\n",
      "Pred:[0 1 1 0 1 1 1 1]\n",
      "True:[0 1 1 0 0 1 1 1]\n",
      "23 + 80 = 111\n",
      "------------\n",
      "iters:4300\n",
      "Loss:0.5979308197382216\n",
      "Pred:[1 0 0 0 0 1 0 0]\n",
      "True:[1 0 0 1 0 1 0 0]\n",
      "56 + 92 = 132\n",
      "------------\n",
      "iters:4400\n",
      "Loss:1.1146976026034168\n",
      "Pred:[1 1 1 1 0 1 0 1]\n",
      "True:[1 0 0 0 1 0 0 1]\n",
      "110 + 27 = 245\n",
      "------------\n",
      "iters:4500\n",
      "Loss:0.5511665326964982\n",
      "Pred:[0 1 1 1 0 1 1 1]\n",
      "True:[0 1 0 0 0 1 1 1]\n",
      "25 + 46 = 119\n",
      "------------\n",
      "iters:4600\n",
      "Loss:0.7431583934770121\n",
      "Pred:[0 1 1 1 1 1 1 0]\n",
      "True:[0 1 1 1 0 0 0 0]\n",
      "43 + 69 = 126\n",
      "------------\n",
      "iters:4700\n",
      "Loss:1.099944901983434\n",
      "Pred:[1 0 0 0 0 0 0 1]\n",
      "True:[1 1 1 0 1 0 0 1]\n",
      "110 + 123 = 129\n",
      "------------\n",
      "iters:4800\n",
      "Loss:0.54100473979622\n",
      "Pred:[0 0 1 1 1 0 1 1]\n",
      "True:[0 0 1 0 0 0 1 1]\n",
      "30 + 5 = 59\n",
      "------------\n",
      "iters:4900\n",
      "Loss:0.912706513457736\n",
      "Pred:[1 1 1 0 1 0 1 0]\n",
      "True:[1 0 0 1 0 0 1 0]\n",
      "86 + 60 = 234\n",
      "------------\n",
      "iters:5000\n",
      "Loss:0.92157367931675\n",
      "Pred:[1 0 0 0 0 0 1 1]\n",
      "True:[1 1 1 1 0 0 1 1]\n",
      "122 + 121 = 131\n",
      "------------\n",
      "iters:5100\n",
      "Loss:0.6670391009750122\n",
      "Pred:[0 0 1 1 1 1 1 1]\n",
      "True:[0 0 1 1 0 0 0 0]\n",
      "43 + 5 = 63\n",
      "------------\n",
      "iters:5200\n",
      "Loss:0.18836185941815026\n",
      "Pred:[1 0 0 0 1 0 0 0]\n",
      "True:[1 0 0 0 1 0 0 0]\n",
      "48 + 88 = 136\n",
      "------------\n",
      "iters:5300\n",
      "Loss:0.624900996737204\n",
      "Pred:[1 0 0 0 0 1 1 1]\n",
      "True:[1 0 1 0 0 1 1 1]\n",
      "54 + 113 = 135\n",
      "------------\n",
      "iters:5400\n",
      "Loss:0.6213919176438415\n",
      "Pred:[1 0 1 1 0 0 0 1]\n",
      "True:[1 0 1 1 1 1 0 1]\n",
      "111 + 78 = 177\n",
      "------------\n",
      "iters:5500\n",
      "Loss:0.7210424608551458\n",
      "Pred:[1 0 1 1 0 1 1 1]\n",
      "True:[1 0 1 0 1 1 1 1]\n",
      "76 + 99 = 183\n",
      "------------\n",
      "iters:5600\n",
      "Loss:0.3252915139660508\n",
      "Pred:[0 1 0 1 1 1 1 1]\n",
      "True:[0 1 0 0 1 1 1 1]\n",
      "71 + 8 = 95\n",
      "------------\n",
      "iters:5700\n",
      "Loss:0.14601281265623411\n",
      "Pred:[1 0 0 0 1 0 0 0]\n",
      "True:[1 0 0 0 1 0 0 0]\n",
      "84 + 52 = 136\n",
      "------------\n",
      "iters:5800\n",
      "Loss:0.711292331184433\n",
      "Pred:[1 0 0 0 0 0 0 1]\n",
      "True:[1 0 0 1 0 1 0 1]\n",
      "62 + 87 = 129\n",
      "------------\n",
      "iters:5900\n",
      "Loss:0.30010233038082457\n",
      "Pred:[1 0 0 0 1 0 1 1]\n",
      "True:[1 0 0 0 1 0 1 1]\n",
      "53 + 86 = 139\n",
      "------------\n",
      "iters:6000\n",
      "Loss:0.4751765277073276\n",
      "Pred:[1 0 0 1 1 1 1 1]\n",
      "True:[1 1 0 1 1 1 1 1]\n",
      "120 + 103 = 159\n",
      "------------\n",
      "iters:6100\n",
      "Loss:0.04965855836655069\n",
      "Pred:[0 1 0 1 1 1 1 0]\n",
      "True:[0 1 0 1 1 1 1 0]\n",
      "46 + 48 = 94\n",
      "------------\n",
      "iters:6200\n",
      "Loss:0.3197527344970426\n",
      "Pred:[1 0 0 0 1 1 0 0]\n",
      "True:[1 0 1 0 1 1 0 0]\n",
      "60 + 112 = 140\n",
      "------------\n",
      "iters:6300\n",
      "Loss:0.20963980550275013\n",
      "Pred:[0 0 0 1 1 1 1 1]\n",
      "True:[0 0 0 1 1 1 1 1]\n",
      "23 + 8 = 31\n",
      "------------\n",
      "iters:6400\n",
      "Loss:0.6459301965348421\n",
      "Pred:[1 0 0 0 0 0 0 1]\n",
      "True:[1 1 0 0 0 1 0 1]\n",
      "126 + 71 = 129\n",
      "------------\n",
      "iters:6500\n",
      "Loss:0.018345882613752997\n",
      "Pred:[0 1 0 1 1 1 1 0]\n",
      "True:[0 1 0 1 1 1 1 0]\n",
      "76 + 18 = 94\n",
      "------------\n",
      "iters:6600\n",
      "Loss:0.35395155821268054\n",
      "Pred:[0 1 1 0 1 1 0 1]\n",
      "True:[0 1 1 0 1 1 0 0]\n",
      "41 + 67 = 109\n",
      "------------\n",
      "iters:6700\n",
      "Loss:0.019341410805700666\n",
      "Pred:[0 0 1 0 1 0 0 0]\n",
      "True:[0 0 1 0 1 0 0 0]\n",
      "36 + 4 = 40\n",
      "------------\n",
      "iters:6800\n",
      "Loss:0.3574195681413349\n",
      "Pred:[1 0 0 0 0 1 0 1]\n",
      "True:[1 0 1 0 0 1 0 1]\n",
      "121 + 44 = 133\n",
      "------------\n",
      "iters:6900\n",
      "Loss:0.5039144125159947\n",
      "Pred:[1 0 0 0 1 1 0 1]\n",
      "True:[1 1 0 0 1 1 0 0]\n",
      "91 + 113 = 141\n",
      "------------\n",
      "iters:7000\n",
      "Loss:0.582264933714587\n",
      "Pred:[0 1 0 1 0 0 0 1]\n",
      "True:[0 1 0 1 0 1 1 0]\n",
      "39 + 47 = 81\n",
      "------------\n",
      "iters:7100\n",
      "Loss:0.07900804906296785\n",
      "Pred:[1 0 1 1 1 1 0 1]\n",
      "True:[1 0 1 1 1 1 0 1]\n",
      "81 + 108 = 189\n",
      "------------\n",
      "iters:7200\n",
      "Loss:0.2858192754550031\n",
      "Pred:[0 1 1 0 0 0 0 1]\n",
      "True:[0 1 1 0 0 0 0 1]\n",
      "66 + 31 = 97\n",
      "------------\n",
      "iters:7300\n",
      "Loss:0.7265720811848516\n",
      "Pred:[1 0 0 0 0 0 0 1]\n",
      "True:[1 0 1 1 0 0 0 0]\n",
      "121 + 55 = 129\n",
      "------------\n",
      "iters:7400\n",
      "Loss:0.009902801785220142\n",
      "Pred:[0 1 0 0 1 1 1 0]\n",
      "True:[0 1 0 0 1 1 1 0]\n",
      "64 + 14 = 78\n",
      "------------\n",
      "iters:7500\n",
      "Loss:0.41821864782015733\n",
      "Pred:[0 1 0 0 1 1 1 1]\n",
      "True:[0 1 1 0 1 1 1 0]\n",
      "53 + 57 = 79\n",
      "------------\n",
      "iters:7600\n",
      "Loss:0.13355688190752257\n",
      "Pred:[0 0 1 0 0 0 1 1]\n",
      "True:[0 0 1 0 0 0 1 1]\n",
      "18 + 17 = 35\n",
      "------------\n",
      "iters:7700\n",
      "Loss:0.2734331474628932\n",
      "Pred:[1 0 0 0 1 1 0 1]\n",
      "True:[1 0 1 0 1 1 0 1]\n",
      "117 + 56 = 141\n",
      "------------\n",
      "iters:7800\n",
      "Loss:0.3414938171330099\n",
      "Pred:[1 0 1 1 0 0 0 0]\n",
      "True:[1 0 1 1 0 1 0 0]\n",
      "94 + 86 = 176\n",
      "------------\n",
      "iters:7900\n",
      "Loss:0.4031960461558365\n",
      "Pred:[0 1 1 0 1 0 0 1]\n",
      "True:[0 1 1 0 1 0 0 1]\n",
      "46 + 59 = 105\n",
      "------------\n",
      "iters:8000\n",
      "Loss:0.03843609857220462\n",
      "Pred:[0 1 0 0 1 0 1 0]\n",
      "True:[0 1 0 0 1 0 1 0]\n",
      "18 + 56 = 74\n",
      "------------\n",
      "iters:8100\n",
      "Loss:0.0557577168920931\n",
      "Pred:[1 0 1 1 0 1 1 1]\n",
      "True:[1 0 1 1 0 1 1 1]\n",
      "65 + 118 = 183\n",
      "------------\n",
      "iters:8200\n",
      "Loss:0.028338934328518882\n",
      "Pred:[0 1 0 0 1 1 1 0]\n",
      "True:[0 1 0 0 1 1 1 0]\n",
      "20 + 58 = 78\n",
      "------------\n",
      "iters:8300\n",
      "Loss:0.009490362553148411\n",
      "Pred:[0 1 0 0 0 1 0 0]\n",
      "True:[0 1 0 0 0 1 0 0]\n",
      "32 + 36 = 68\n",
      "------------\n",
      "iters:8400\n",
      "Loss:0.18224269046786523\n",
      "Pred:[1 1 1 0 1 0 1 0]\n",
      "True:[1 1 1 0 1 0 1 0]\n",
      "116 + 118 = 234\n",
      "------------\n",
      "iters:8500\n",
      "Loss:0.08267253560203701\n",
      "Pred:[1 0 1 1 0 0 0 1]\n",
      "True:[1 0 1 1 0 0 0 1]\n",
      "101 + 76 = 177\n",
      "------------\n",
      "iters:8600\n",
      "Loss:0.09043103693956044\n",
      "Pred:[0 0 1 1 1 1 0 1]\n",
      "True:[0 0 1 1 1 1 0 1]\n",
      "35 + 26 = 61\n",
      "------------\n",
      "iters:8700\n",
      "Loss:0.11551858244229865\n",
      "Pred:[1 0 0 0 0 0 0 1]\n",
      "True:[1 0 0 0 0 0 0 1]\n",
      "23 + 106 = 129\n",
      "------------\n",
      "iters:8800\n",
      "Loss:0.14643388833907434\n",
      "Pred:[1 0 0 0 0 0 1 1]\n",
      "True:[1 0 0 0 0 0 1 1]\n",
      "14 + 117 = 131\n",
      "------------\n",
      "iters:8900\n",
      "Loss:0.1888355821721337\n",
      "Pred:[0 0 1 1 1 1 0 1]\n",
      "True:[0 0 1 1 1 1 0 1]\n",
      "14 + 47 = 61\n",
      "------------\n",
      "iters:9000\n",
      "Loss:0.39539105097347793\n",
      "Pred:[0 1 1 0 1 0 0 1]\n",
      "True:[0 1 1 0 1 0 0 0]\n",
      "49 + 55 = 105\n",
      "------------\n",
      "iters:9100\n",
      "Loss:0.023468559249938833\n",
      "Pred:[0 1 0 1 1 0 1 1]\n",
      "True:[0 1 0 1 1 0 1 1]\n",
      "17 + 74 = 91\n",
      "------------\n",
      "iters:9200\n",
      "Loss:0.07096659939771263\n",
      "Pred:[1 0 1 0 1 0 0 0]\n",
      "True:[1 0 1 0 1 0 0 0]\n",
      "76 + 92 = 168\n",
      "------------\n",
      "iters:9300\n",
      "Loss:0.03158714869931252\n",
      "Pred:[0 0 1 1 0 1 1 1]\n",
      "True:[0 0 1 1 0 1 1 1]\n",
      "3 + 52 = 55\n",
      "------------\n",
      "iters:9400\n",
      "Loss:0.1283475189372982\n",
      "Pred:[0 1 1 0 0 0 1 1]\n",
      "True:[0 1 1 0 0 0 1 1]\n",
      "52 + 47 = 99\n",
      "------------\n",
      "iters:9500\n",
      "Loss:0.06600788963822325\n",
      "Pred:[0 1 0 1 0 1 0 1]\n",
      "True:[0 1 0 1 0 1 0 1]\n",
      "52 + 33 = 85\n",
      "------------\n",
      "iters:9600\n",
      "Loss:0.04764570340355377\n",
      "Pred:[1 0 0 0 1 1 1 1]\n",
      "True:[1 0 0 0 1 1 1 1]\n",
      "66 + 77 = 143\n",
      "------------\n",
      "iters:9700\n",
      "Loss:0.06919064372803942\n",
      "Pred:[1 0 1 1 1 1 0 1]\n",
      "True:[1 0 1 1 1 1 0 1]\n",
      "98 + 91 = 189\n",
      "------------\n",
      "iters:9800\n",
      "Loss:0.25339755708417155\n",
      "Pred:[1 0 1 0 1 1 0 1]\n",
      "True:[1 0 1 0 1 1 0 0]\n",
      "119 + 53 = 173\n",
      "------------\n",
      "iters:9900\n",
      "Loss:0.0058883250623857145\n",
      "Pred:[0 1 1 0 0 1 1 0]\n",
      "True:[0 1 1 0 0 1 1 0]\n",
      "92 + 10 = 102\n",
      "------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from common import functions\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# def d_tanh(x):\n",
    "\n",
    "\n",
    "\n",
    "# データを用意\n",
    "# 2進数の桁数\n",
    "binary_dim = 8\n",
    "# 最大値 + 1\n",
    "largest_number = pow(2, binary_dim)\n",
    "# largest_numberまで2進数を用意\n",
    "binary = np.unpackbits(np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n",
    "\n",
    "input_layer_size = 2\n",
    "hidden_layer_size = 16\n",
    "output_layer_size = 1\n",
    "\n",
    "weight_init_std = 1\n",
    "learning_rate = 0.1\n",
    "\n",
    "iters_num = 10000\n",
    "plot_interval = 100\n",
    "\n",
    "# Xavier\n",
    "W_in = weight_init_std * np.random.randn(input_layer_size, hidden_layer_size)/np.sqrt(input_layer_size)\n",
    "W_out = weight_init_std * np.random.randn(hidden_layer_size, output_layer_size)/np.sqrt(input_layer_size)\n",
    "W = weight_init_std * np.random.randn(hidden_layer_size, hidden_layer_size)/np.sqrt(input_layer_size)\n",
    "\n",
    "# Xavier\n",
    "\n",
    "\n",
    "# He\n",
    "\n",
    "\n",
    "\n",
    "# 勾配\n",
    "W_in_grad = np.zeros_like(W_in)\n",
    "W_out_grad = np.zeros_like(W_out)\n",
    "W_grad = np.zeros_like(W)\n",
    "\n",
    "u = np.zeros((hidden_layer_size, binary_dim + 1))\n",
    "z = np.zeros((hidden_layer_size, binary_dim + 1))\n",
    "y = np.zeros((output_layer_size, binary_dim))\n",
    "\n",
    "delta_out = np.zeros((output_layer_size, binary_dim))\n",
    "delta = np.zeros((hidden_layer_size, binary_dim + 1))\n",
    "\n",
    "all_losses = []\n",
    "\n",
    "for i in range(iters_num):\n",
    "    \n",
    "    # A, B初期化 (a + b = d)\n",
    "    a_int = np.random.randint(largest_number/2)\n",
    "    a_bin = binary[a_int] # binary encoding\n",
    "    b_int = np.random.randint(largest_number/2)\n",
    "    b_bin = binary[b_int] # binary encoding\n",
    "    \n",
    "    # 正解データ\n",
    "    d_int = a_int + b_int\n",
    "    d_bin = binary[d_int]\n",
    "    \n",
    "    # 出力バイナリ\n",
    "    out_bin = np.zeros_like(d_bin)\n",
    "    \n",
    "    # 時系列全体の誤差\n",
    "    all_loss = 0    \n",
    "    \n",
    "    # 時系列ループ\n",
    "    for t in range(binary_dim):\n",
    "        # 入力値\n",
    "        X = np.array([a_bin[ - t - 1], b_bin[ - t - 1]]).reshape(1, -1)\n",
    "        # 時刻tにおける正解データ\n",
    "        dd = np.array([d_bin[binary_dim - t - 1]])\n",
    "        \n",
    "        u[:,t+1] = np.dot(X, W_in) + np.dot(z[:,t].reshape(1, -1), W)\n",
    "        z[:,t+1] = functions.sigmoid(u[:,t+1])\n",
    "\n",
    "        y[:,t] = functions.sigmoid(np.dot(z[:,t+1].reshape(1, -1), W_out))\n",
    "\n",
    "\n",
    "        #誤差\n",
    "        loss = functions.mean_squared_error(dd, y[:,t])\n",
    "        \n",
    "        delta_out[:,t] = functions.d_mean_squared_error(dd, y[:,t]) * functions.d_sigmoid(y[:,t])        \n",
    "        \n",
    "        all_loss += loss\n",
    "\n",
    "        out_bin[binary_dim - t - 1] = np.round(y[:,t])\n",
    "    \n",
    "    \n",
    "    for t in range(binary_dim)[::-1]:\n",
    "        X = np.array([a_bin[-t-1],b_bin[-t-1]]).reshape(1, -1)        \n",
    "\n",
    "        delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_sigmoid(u[:,t+1])\n",
    "\n",
    "        # 勾配更新\n",
    "        W_out_grad += np.dot(z[:,t+1].reshape(-1,1), delta_out[:,t].reshape(-1,1))\n",
    "        W_grad += np.dot(z[:,t].reshape(-1,1), delta[:,t].reshape(1,-1))\n",
    "        W_in_grad += np.dot(X.T, delta[:,t].reshape(1,-1))\n",
    "    \n",
    "    # 勾配適用\n",
    "    W_in -= learning_rate * W_in_grad\n",
    "    W_out -= learning_rate * W_out_grad\n",
    "    W -= learning_rate * W_grad\n",
    "    \n",
    "    W_in_grad *= 0\n",
    "    W_out_grad *= 0\n",
    "    W_grad *= 0\n",
    "    \n",
    "\n",
    "    if(i % plot_interval == 0):\n",
    "        all_losses.append(all_loss)        \n",
    "        print(\"iters:\" + str(i))\n",
    "        print(\"Loss:\" + str(all_loss))\n",
    "        print(\"Pred:\" + str(out_bin))\n",
    "        print(\"True:\" + str(d_bin))\n",
    "        out_int = 0\n",
    "        for index,x in enumerate(reversed(out_bin)):\n",
    "            out_int += x * pow(2, index)\n",
    "        print(str(a_int) + \" + \" + str(b_int) + \" = \" + str(out_int))\n",
    "        print(\"------------\")\n",
    "\n",
    "lists = range(0, iters_num, plot_interval)\n",
    "plt.plot(lists, all_losses, label=\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iters:0\n",
      "Loss:5.906679322269037\n",
      "Pred:[255 255 255   1 255 255 255   0]\n",
      "True:[0 1 0 1 0 0 1 0]\n",
      "56 + 26 = 60706\n",
      "------------\n",
      "iters:100\n",
      "Loss:1.2618984722929607\n",
      "Pred:[0 1 1 1 1 1 1 1]\n",
      "True:[1 0 0 1 0 1 1 1]\n",
      "63 + 88 = 127\n",
      "------------\n",
      "iters:200\n",
      "Loss:1.1348885906577268\n",
      "Pred:[0 1 0 0 1 1 0 1]\n",
      "True:[0 1 0 0 0 0 0 1]\n",
      "44 + 21 = 77\n",
      "------------\n",
      "iters:300\n",
      "Loss:2.375861873870769\n",
      "Pred:[255   1   1   1   1   0   1   1]\n",
      "True:[1 1 0 1 1 0 1 1]\n",
      "116 + 103 = 32763\n",
      "------------\n",
      "iters:400\n",
      "Loss:0.9027784227159417\n",
      "Pred:[0 0 1 1 1 1 1 1]\n",
      "True:[1 0 1 0 1 1 1 1]\n",
      "83 + 92 = 63\n",
      "------------\n",
      "iters:500\n",
      "Loss:1.2770955608737071\n",
      "Pred:[1 1 0 1 1 0 1 0]\n",
      "True:[0 1 1 0 1 0 1 1]\n",
      "90 + 17 = 218\n",
      "------------\n",
      "iters:600\n",
      "Loss:0.3874877439938075\n",
      "Pred:[0 1 1 1 1 1 1 0]\n",
      "True:[0 1 1 1 1 1 1 0]\n",
      "122 + 4 = 126\n",
      "------------\n",
      "iters:700\n",
      "Loss:1.2024417645408199\n",
      "Pred:[1 0 1 1 1 1 1 1]\n",
      "True:[1 0 0 1 1 1 1 0]\n",
      "97 + 61 = 191\n",
      "------------\n",
      "iters:800\n",
      "Loss:2.02515414621677\n",
      "Pred:[1 0 1 0 1 0 1 1]\n",
      "True:[1 1 0 0 0 1 0 0]\n",
      "105 + 91 = 171\n",
      "------------\n",
      "iters:900\n",
      "Loss:0.7795644747061844\n",
      "Pred:[1 1 1 1 1 1 1 1]\n",
      "True:[0 1 1 0 1 1 1 1]\n",
      "101 + 10 = 255\n",
      "------------\n",
      "iters:1000\n",
      "Loss:0.8532233116636173\n",
      "Pred:[0 0 1 1 1 1 0 0]\n",
      "True:[0 1 0 1 1 1 1 0]\n",
      "84 + 10 = 60\n",
      "------------\n",
      "iters:1100\n",
      "Loss:2.0221926878977086\n",
      "Pred:[0 0 0 0 0 0 1 1]\n",
      "True:[0 1 1 1 0 1 0 0]\n",
      "49 + 67 = 3\n",
      "------------\n",
      "iters:1200\n",
      "Loss:1.2770490016506242\n",
      "Pred:[0 1 1 1 1 1 1 1]\n",
      "True:[1 0 0 1 0 0 1 1]\n",
      "114 + 33 = 127\n",
      "------------\n",
      "iters:1300\n",
      "Loss:0.9715807658220851\n",
      "Pred:[0 0 0 1 0 0 1 1]\n",
      "True:[0 0 0 1 1 0 0 1]\n",
      "2 + 23 = 19\n",
      "------------\n",
      "iters:1400\n",
      "Loss:0.8423496120827332\n",
      "Pred:[1 1 1 0 1 0 1 1]\n",
      "True:[0 0 0 0 1 0 1 1]\n",
      "1 + 10 = 235\n",
      "------------\n",
      "iters:1500\n",
      "Loss:0.9982048112501425\n",
      "Pred:[0 1 1 1 1 1 1 1]\n",
      "True:[1 1 0 1 0 1 1 0]\n",
      "87 + 127 = 127\n",
      "------------\n",
      "iters:1600\n",
      "Loss:1.361104614881773\n",
      "Pred:[0 1 0 1 1 1 1 1]\n",
      "True:[1 0 1 1 1 1 0 0]\n",
      "93 + 95 = 95\n",
      "------------\n",
      "iters:1700\n",
      "Loss:1.1104380078146616\n",
      "Pred:[0 0 1 0 0 1 1 0]\n",
      "True:[0 1 1 1 0 0 0 0]\n",
      "59 + 53 = 38\n",
      "------------\n",
      "iters:1800\n",
      "Loss:1.0539262470988011\n",
      "Pred:[1 1 1 0 0 0 1 0]\n",
      "True:[1 1 1 1 0 0 0 1]\n",
      "115 + 126 = 226\n",
      "------------\n",
      "iters:1900\n",
      "Loss:0.8064025503864831\n",
      "Pred:[0 1 1 0 0 1 0 0]\n",
      "True:[0 1 1 1 0 1 1 0]\n",
      "38 + 80 = 100\n",
      "------------\n",
      "iters:2000\n",
      "Loss:0.7951586083566798\n",
      "Pred:[0 1 0 0 1 0 1 0]\n",
      "True:[0 1 1 0 1 0 1 0]\n",
      "2 + 104 = 74\n",
      "------------\n",
      "iters:2100\n",
      "Loss:0.895262022629451\n",
      "Pred:[0 1 1 0 1 1 0 0]\n",
      "True:[1 0 0 0 0 0 0 0]\n",
      "100 + 28 = 108\n",
      "------------\n",
      "iters:2200\n",
      "Loss:1.248494993344145\n",
      "Pred:[0 0 0 0 1 0 0 1]\n",
      "True:[0 1 0 0 0 1 1 1]\n",
      "9 + 62 = 9\n",
      "------------\n",
      "iters:2300\n",
      "Loss:1.128849873586295\n",
      "Pred:[1 1 1 0 0 0 1 1]\n",
      "True:[1 0 0 1 0 0 0 0]\n",
      "47 + 97 = 227\n",
      "------------\n",
      "iters:2400\n",
      "Loss:1.3003592762251546\n",
      "Pred:[1 1 1 1 0 0 1 0]\n",
      "True:[1 0 0 0 1 1 1 1]\n",
      "24 + 119 = 242\n",
      "------------\n",
      "iters:2500\n",
      "Loss:1.0294682068949816\n",
      "Pred:[1 1 1 1 1 1 1 1]\n",
      "True:[0 1 0 0 1 1 0 1]\n",
      "5 + 72 = 255\n",
      "------------\n",
      "iters:2600\n",
      "Loss:1.055380868353013\n",
      "Pred:[0 0 0 1 0 1 1 0]\n",
      "True:[1 1 0 0 0 1 0 0]\n",
      "118 + 78 = 22\n",
      "------------\n",
      "iters:2700\n",
      "Loss:0.8903375903192547\n",
      "Pred:[1 1 1 0 0 1 0 0]\n",
      "True:[0 1 1 1 0 1 0 1]\n",
      "48 + 69 = 228\n",
      "------------\n",
      "iters:2800\n",
      "Loss:0.9081673951345917\n",
      "Pred:[0 1 1 1 1 0 0 0]\n",
      "True:[1 0 0 0 1 0 0 1]\n",
      "40 + 97 = 120\n",
      "------------\n",
      "iters:2900\n",
      "Loss:0.963026939077187\n",
      "Pred:[0 1 1 1 1 1 0 0]\n",
      "True:[0 1 0 1 0 0 1 0]\n",
      "58 + 24 = 124\n",
      "------------\n",
      "iters:3000\n",
      "Loss:1.0762535831162015\n",
      "Pred:[0 1 0 0 1 0 0 0]\n",
      "True:[0 1 0 1 1 1 1 0]\n",
      "91 + 3 = 72\n",
      "------------\n",
      "iters:3100\n",
      "Loss:1.0710755393676106\n",
      "Pred:[0 1 0 1 1 1 1 1]\n",
      "True:[1 0 0 0 0 1 1 0]\n",
      "57 + 77 = 95\n",
      "------------\n",
      "iters:3200\n",
      "Loss:0.8556955940940087\n",
      "Pred:[0 1 0 0 1 1 1 1]\n",
      "True:[0 1 1 0 0 0 1 1]\n",
      "28 + 71 = 79\n",
      "------------\n",
      "iters:3300\n",
      "Loss:0.9460718871366252\n",
      "Pred:[0 0 1 1 0 1 1 0]\n",
      "True:[0 1 1 1 0 0 0 0]\n",
      "58 + 54 = 54\n",
      "------------\n",
      "iters:3400\n",
      "Loss:0.859158839252426\n",
      "Pred:[1 1 1 0 1 1 1 0]\n",
      "True:[0 1 1 1 1 1 1 0]\n",
      "115 + 11 = 238\n",
      "------------\n",
      "iters:3500\n",
      "Loss:0.8159028431146587\n",
      "Pred:[1 1 1 1 0 0 1 0]\n",
      "True:[1 0 0 1 0 0 1 0]\n",
      "96 + 50 = 242\n",
      "------------\n",
      "iters:3600\n",
      "Loss:1.1692116790157603\n",
      "Pred:[1 1 1 1 1 1 1 1]\n",
      "True:[0 1 0 1 0 0 0 1]\n",
      "77 + 4 = 255\n",
      "------------\n",
      "iters:3700\n",
      "Loss:0.8975037612545452\n",
      "Pred:[1 1 1 1 1 1 1 1]\n",
      "True:[0 1 0 1 1 0 0 1]\n",
      "77 + 12 = 255\n",
      "------------\n",
      "iters:3800\n",
      "Loss:0.7713125958709495\n",
      "Pred:[1 0 1 0 1 0 0 0]\n",
      "True:[0 0 1 1 1 0 0 0]\n",
      "26 + 30 = 168\n",
      "------------\n",
      "iters:3900\n",
      "Loss:0.8999498998778567\n",
      "Pred:[0 1 1 0 1 1 1 1]\n",
      "True:[0 0 1 0 1 0 1 1]\n",
      "4 + 39 = 111\n",
      "------------\n",
      "iters:4000\n",
      "Loss:0.8789508697328031\n",
      "Pred:[0 1 0 0 1 1 1 0]\n",
      "True:[0 1 1 0 0 0 1 0]\n",
      "50 + 48 = 78\n",
      "------------\n",
      "iters:4100\n",
      "Loss:0.885042032097994\n",
      "Pred:[0 1 0 1 1 0 1 0]\n",
      "True:[1 1 0 0 0 0 1 0]\n",
      "98 + 96 = 90\n",
      "------------\n",
      "iters:4200\n",
      "Loss:0.9312803961796225\n",
      "Pred:[0 0 1 0 0 0 0 0]\n",
      "True:[0 1 0 1 0 1 0 0]\n",
      "74 + 10 = 32\n",
      "------------\n",
      "iters:4300\n",
      "Loss:1.02445027082917\n",
      "Pred:[1 1 1 1 1 1 1 1]\n",
      "True:[0 1 1 1 1 0 0 0]\n",
      "55 + 65 = 255\n",
      "------------\n",
      "iters:4400\n",
      "Loss:0.9559023695262168\n",
      "Pred:[1 1 1 1 0 1 1 0]\n",
      "True:[1 1 0 1 0 0 0 0]\n",
      "114 + 94 = 246\n",
      "------------\n",
      "iters:4500\n",
      "Loss:0.8990128928966843\n",
      "Pred:[0 0 0 0 0 0 1 1]\n",
      "True:[0 1 0 1 0 0 1 0]\n",
      "81 + 1 = 3\n",
      "------------\n",
      "iters:4600\n",
      "Loss:0.9905375639216214\n",
      "Pred:[1 1 1 0 1 1 0 0]\n",
      "True:[0 1 1 1 0 1 1 1]\n",
      "49 + 70 = 236\n",
      "------------\n",
      "iters:4700\n",
      "Loss:0.5848887528086245\n",
      "Pred:[0 0 0 1 1 1 1 0]\n",
      "True:[0 1 1 1 1 1 1 0]\n",
      "52 + 74 = 30\n",
      "------------\n",
      "iters:4800\n",
      "Loss:1.1519035378876796\n",
      "Pred:[0 1 0 0 1 1 1 1]\n",
      "True:[1 0 0 1 0 1 0 0]\n",
      "125 + 23 = 79\n",
      "------------\n",
      "iters:4900\n",
      "Loss:1.1015348157848237\n",
      "Pred:[0 0 1 1 1 1 1 1]\n",
      "True:[1 0 1 0 1 0 1 1]\n",
      "110 + 61 = 63\n",
      "------------\n",
      "iters:5000\n",
      "Loss:0.7284983051598221\n",
      "Pred:[1 0 1 1 0 1 1 0]\n",
      "True:[1 0 0 1 1 1 1 1]\n",
      "111 + 48 = 182\n",
      "------------\n",
      "iters:5100\n",
      "Loss:1.1518899106625329\n",
      "Pred:[0 1 1 1 0 0 0 1]\n",
      "True:[1 0 1 1 1 0 1 0]\n",
      "67 + 119 = 113\n",
      "------------\n",
      "iters:5200\n",
      "Loss:0.9878357037839465\n",
      "Pred:[0 1 1 1 0 1 1 0]\n",
      "True:[1 0 0 1 0 1 0 0]\n",
      "50 + 98 = 118\n",
      "------------\n",
      "iters:5300\n",
      "Loss:1.1362908057662697\n",
      "Pred:[0 0 1 0 1 0 1 0]\n",
      "True:[0 1 1 1 1 1 0 1]\n",
      "110 + 15 = 42\n",
      "------------\n",
      "iters:5400\n",
      "Loss:1.3474841418148906\n",
      "Pred:[0 0 1 0 1 1 0 1]\n",
      "True:[0 1 0 1 0 0 0 0]\n",
      "77 + 3 = 45\n",
      "------------\n",
      "iters:5500\n",
      "Loss:0.9294453448448604\n",
      "Pred:[1 1 1 0 1 1 0 0]\n",
      "True:[1 0 0 0 0 1 0 0]\n",
      "106 + 26 = 236\n",
      "------------\n",
      "iters:5600\n",
      "Loss:1.0767663391713977\n",
      "Pred:[0 1 1 0 1 1 0 1]\n",
      "True:[1 0 0 1 1 1 0 1]\n",
      "79 + 78 = 109\n",
      "------------\n",
      "iters:5700\n",
      "Loss:0.9962033906272707\n",
      "Pred:[0 1 1 1 1 1 1 0]\n",
      "True:[0 1 0 1 0 0 1 0]\n",
      "82 + 0 = 126\n",
      "------------\n",
      "iters:5800\n",
      "Loss:0.9748935540397166\n",
      "Pred:[1 1 1 1 1 0 1 0]\n",
      "True:[1 1 0 1 0 0 1 1]\n",
      "104 + 107 = 250\n",
      "------------\n",
      "iters:5900\n",
      "Loss:0.9865979875738176\n",
      "Pred:[1 1 1 0 1 1 1 0]\n",
      "True:[1 0 0 0 1 0 1 0]\n",
      "50 + 88 = 238\n",
      "------------\n",
      "iters:6000\n",
      "Loss:1.0063178504935453\n",
      "Pred:[1 0 1 0 1 1 0 1]\n",
      "True:[0 1 1 0 0 1 1 1]\n",
      "39 + 64 = 173\n",
      "------------\n",
      "iters:6100\n",
      "Loss:0.8479234765707904\n",
      "Pred:[0 0 0 0 1 1 0 1]\n",
      "True:[0 1 0 0 1 1 0 1]\n",
      "63 + 14 = 13\n",
      "------------\n",
      "iters:6200\n",
      "Loss:1.2307154259102264\n",
      "Pred:[0 1 0 1 1 0 1 1]\n",
      "True:[1 0 1 1 0 0 0 1]\n",
      "91 + 86 = 91\n",
      "------------\n",
      "iters:6300\n",
      "Loss:0.8590274928703328\n",
      "Pred:[1 1 1 1 0 1 1 0]\n",
      "True:[1 0 1 0 0 1 1 0]\n",
      "42 + 124 = 246\n",
      "------------\n",
      "iters:6400\n",
      "Loss:0.9171754680639259\n",
      "Pred:[1 1 1 1 1 0 1 0]\n",
      "True:[0 1 1 1 0 0 1 0]\n",
      "104 + 10 = 250\n",
      "------------\n",
      "iters:6500\n",
      "Loss:1.1222795103659542\n",
      "Pred:[0 1 0 0 1 0 1 1]\n",
      "True:[1 0 1 1 0 0 1 1]\n",
      "59 + 120 = 75\n",
      "------------\n",
      "iters:6600\n",
      "Loss:1.2468456174306015\n",
      "Pred:[1 1 1 0 1 1 1 1]\n",
      "True:[1 0 0 1 1 1 1 0]\n",
      "45 + 113 = 239\n",
      "------------\n",
      "iters:6700\n",
      "Loss:1.4592074632451355\n",
      "Pred:[0 1 0 0 0 1 0 1]\n",
      "True:[1 0 1 0 1 0 1 0]\n",
      "69 + 101 = 69\n",
      "------------\n",
      "iters:6800\n",
      "Loss:1.1547998112460716\n",
      "Pred:[0 1 1 0 1 0 1 0]\n",
      "True:[1 0 0 0 0 1 1 0]\n",
      "50 + 84 = 106\n",
      "------------\n",
      "iters:6900\n",
      "Loss:1.239020988696308\n",
      "Pred:[0 0 1 0 1 0 0 0]\n",
      "True:[1 0 0 0 0 1 1 1]\n",
      "72 + 63 = 40\n",
      "------------\n",
      "iters:7000\n",
      "Loss:1.0459821030598928\n",
      "Pred:[1 0 0 1 1 0 1 1]\n",
      "True:[0 1 1 1 1 1 1 1]\n",
      "116 + 11 = 155\n",
      "------------\n",
      "iters:7100\n",
      "Loss:0.5688708261046108\n",
      "Pred:[0 1 1 1 1 1 1 0]\n",
      "True:[0 1 0 1 0 1 1 0]\n",
      "76 + 10 = 126\n",
      "------------\n",
      "iters:7200\n",
      "Loss:0.8094296190171497\n",
      "Pred:[0 1 0 0 0 0 1 0]\n",
      "True:[0 1 1 0 0 0 0 0]\n",
      "94 + 2 = 66\n",
      "------------\n",
      "iters:7300\n",
      "Loss:1.0812420592450458\n",
      "Pred:[1 0 1 0 0 1 0 1]\n",
      "True:[1 1 0 0 1 1 1 1]\n",
      "99 + 108 = 165\n",
      "------------\n",
      "iters:7400\n",
      "Loss:1.2445615814906286\n",
      "Pred:[1 1 1 0 1 0 0 1]\n",
      "True:[0 1 1 1 0 0 0 0]\n",
      "43 + 69 = 233\n",
      "------------\n",
      "iters:7500\n",
      "Loss:0.7523291053749601\n",
      "Pred:[0 1 1 1 0 0 0 0]\n",
      "True:[1 0 1 1 0 0 1 0]\n",
      "52 + 126 = 112\n",
      "------------\n",
      "iters:7600\n",
      "Loss:0.8038061140037824\n",
      "Pred:[1 1 1 1 1 1 1 0]\n",
      "True:[0 0 1 1 1 0 1 0]\n",
      "2 + 56 = 254\n",
      "------------\n",
      "iters:7700\n",
      "Loss:0.9724988848915823\n",
      "Pred:[1 1 0 1 1 1 0 0]\n",
      "True:[0 0 0 1 0 1 1 0]\n",
      "4 + 18 = 220\n",
      "------------\n",
      "iters:7800\n",
      "Loss:0.8910842537257467\n",
      "Pred:[1 0 1 0 0 0 1 1]\n",
      "True:[1 0 1 0 1 0 0 0]\n",
      "67 + 101 = 163\n",
      "------------\n",
      "iters:7900\n",
      "Loss:0.8748809272143574\n",
      "Pred:[0 1 1 0 1 1 1 0]\n",
      "True:[0 1 0 1 0 1 1 0]\n",
      "18 + 68 = 110\n",
      "------------\n",
      "iters:8000\n",
      "Loss:0.853166673351898\n",
      "Pred:[1 1 0 0 1 1 1 0]\n",
      "True:[0 1 1 0 1 0 1 0]\n",
      "94 + 12 = 206\n",
      "------------\n",
      "iters:8100\n",
      "Loss:0.7236540664009093\n",
      "Pred:[0 1 1 1 1 1 0 1]\n",
      "True:[0 1 1 1 0 1 0 1]\n",
      "117 + 0 = 125\n",
      "------------\n",
      "iters:8200\n",
      "Loss:0.869019789331127\n",
      "Pred:[1 0 1 1 0 0 1 1]\n",
      "True:[1 0 0 1 0 0 0 1]\n",
      "47 + 98 = 179\n",
      "------------\n",
      "iters:8300\n",
      "Loss:0.9050494217375725\n",
      "Pred:[1 1 1 0 1 1 1 1]\n",
      "True:[1 0 0 0 1 1 1 1]\n",
      "87 + 56 = 239\n",
      "------------\n",
      "iters:8400\n",
      "Loss:1.1360575202662546\n",
      "Pred:[0 0 0 1 1 1 1 1]\n",
      "True:[0 0 1 0 1 0 0 0]\n",
      "5 + 35 = 31\n",
      "------------\n",
      "iters:8500\n",
      "Loss:1.2823986274477834\n",
      "Pred:[0 1 0 1 0 0 0 1]\n",
      "True:[1 0 0 0 0 0 1 0]\n",
      "99 + 31 = 81\n",
      "------------\n",
      "iters:8600\n",
      "Loss:0.8847217602324217\n",
      "Pred:[0 0 1 0 0 1 1 0]\n",
      "True:[1 0 0 0 1 0 1 0]\n",
      "66 + 72 = 38\n",
      "------------\n",
      "iters:8700\n",
      "Loss:1.0905738882025164\n",
      "Pred:[1 0 1 1 1 0 1 1]\n",
      "True:[0 1 1 1 1 0 1 0]\n",
      "51 + 71 = 187\n",
      "------------\n",
      "iters:8800\n",
      "Loss:0.5482296298352767\n",
      "Pred:[0 1 1 0 1 1 0 0]\n",
      "True:[0 1 0 0 1 1 0 0]\n",
      "44 + 32 = 108\n",
      "------------\n",
      "iters:8900\n",
      "Loss:0.9917438539084197\n",
      "Pred:[1 1 1 1 0 1 1 1]\n",
      "True:[0 1 1 0 0 0 1 0]\n",
      "33 + 65 = 247\n",
      "------------\n",
      "iters:9000\n",
      "Loss:1.3401197735252113\n",
      "Pred:[0 1 0 0 1 1 1 1]\n",
      "True:[1 0 1 0 0 0 1 0]\n",
      "85 + 77 = 79\n",
      "------------\n",
      "iters:9100\n",
      "Loss:1.0056132637883928\n",
      "Pred:[1 1 0 1 1 0 1 1]\n",
      "True:[1 0 0 0 1 1 1 1]\n",
      "79 + 64 = 219\n",
      "------------\n",
      "iters:9200\n",
      "Loss:0.8243641074964062\n",
      "Pred:[1 0 1 1 0 1 1 1]\n",
      "True:[1 0 1 0 0 1 0 1]\n",
      "67 + 98 = 183\n",
      "------------\n",
      "iters:9300\n",
      "Loss:1.1174739060714245\n",
      "Pred:[1 1 1 1 1 1 1 1]\n",
      "True:[0 1 1 1 0 0 0 0]\n",
      "111 + 1 = 255\n",
      "------------\n",
      "iters:9400\n",
      "Loss:1.2973411146889064\n",
      "Pred:[0 0 0 0 0 0 0 0]\n",
      "True:[1 1 0 1 1 1 0 1]\n",
      "123 + 98 = 0\n",
      "------------\n",
      "iters:9500\n",
      "Loss:0.951063172421139\n",
      "Pred:[1 1 1 1 0 1 1 0]\n",
      "True:[1 0 0 0 0 0 1 0]\n",
      "95 + 35 = 246\n",
      "------------\n",
      "iters:9600\n",
      "Loss:1.1684211645970453\n",
      "Pred:[1 0 1 1 0 0 1 1]\n",
      "True:[0 1 0 0 0 0 0 0]\n",
      "13 + 51 = 179\n",
      "------------\n",
      "iters:9700\n",
      "Loss:1.1559365618431283\n",
      "Pred:[0 1 1 0 0 1 1 1]\n",
      "True:[0 1 0 1 1 0 0 1]\n",
      "38 + 51 = 103\n",
      "------------\n",
      "iters:9800\n",
      "Loss:1.0131639011805658\n",
      "Pred:[1 1 1 0 1 0 1 1]\n",
      "True:[1 0 0 0 0 0 0 1]\n",
      "50 + 79 = 235\n",
      "------------\n",
      "iters:9900\n",
      "Loss:0.9592665598813304\n",
      "Pred:[0 1 1 0 1 1 0 1]\n",
      "True:[0 1 1 1 1 0 1 1]\n",
      "91 + 32 = 109\n",
      "------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from common import functions\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# def d_tanh(x):\n",
    "\n",
    "\n",
    "\n",
    "# データを用意\n",
    "# 2進数の桁数\n",
    "binary_dim = 8\n",
    "# 最大値 + 1\n",
    "largest_number = pow(2, binary_dim)\n",
    "# largest_numberまで2進数を用意\n",
    "binary = np.unpackbits(np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n",
    "\n",
    "input_layer_size = 2\n",
    "hidden_layer_size = 16\n",
    "output_layer_size = 1\n",
    "\n",
    "weight_init_std = 1\n",
    "learning_rate = 0.01\n",
    "\n",
    "iters_num = 10000\n",
    "plot_interval = 100\n",
    "\n",
    "# ウェイト初期化 (バイアスは簡単のため省略)\n",
    "W_in = weight_init_std * np.random.randn(input_layer_size, hidden_layer_size)\n",
    "W_out = weight_init_std * np.random.randn(hidden_layer_size, output_layer_size)\n",
    "W = weight_init_std * np.random.randn(hidden_layer_size, hidden_layer_size)\n",
    "\n",
    "# Xavier\n",
    "\n",
    "\n",
    "# He\n",
    "\n",
    "\n",
    "\n",
    "# 勾配\n",
    "W_in_grad = np.zeros_like(W_in)\n",
    "W_out_grad = np.zeros_like(W_out)\n",
    "W_grad = np.zeros_like(W)\n",
    "\n",
    "u = np.zeros((hidden_layer_size, binary_dim + 1))\n",
    "z = np.zeros((hidden_layer_size, binary_dim + 1))\n",
    "y = np.zeros((output_layer_size, binary_dim))\n",
    "\n",
    "delta_out = np.zeros((output_layer_size, binary_dim))\n",
    "delta = np.zeros((hidden_layer_size, binary_dim + 1))\n",
    "\n",
    "all_losses = []\n",
    "\n",
    "for i in range(iters_num):\n",
    "    \n",
    "    # A, B初期化 (a + b = d)\n",
    "    a_int = np.random.randint(largest_number/2)\n",
    "    a_bin = binary[a_int] # binary encoding\n",
    "    b_int = np.random.randint(largest_number/2)\n",
    "    b_bin = binary[b_int] # binary encoding\n",
    "    \n",
    "    # 正解データ\n",
    "    d_int = a_int + b_int\n",
    "    d_bin = binary[d_int]\n",
    "    \n",
    "    # 出力バイナリ\n",
    "    out_bin = np.zeros_like(d_bin)\n",
    "    \n",
    "    # 時系列全体の誤差\n",
    "    all_loss = 0    \n",
    "    \n",
    "    # 時系列ループ\n",
    "    for t in range(binary_dim):\n",
    "        # 入力値\n",
    "        X = np.array([a_bin[ - t - 1], b_bin[ - t - 1]]).reshape(1, -1)\n",
    "        # 時刻tにおける正解データ\n",
    "        dd = np.array([d_bin[binary_dim - t - 1]])\n",
    "        \n",
    "        u[:,t+1] = np.dot(X, W_in) + np.dot(z[:,t].reshape(1, -1), W)\n",
    "        z[:,t+1] = np.tanh(u[:,t+1])\n",
    "\n",
    "        y[:,t] = np.tanh(np.dot(z[:,t+1].reshape(1, -1), W_out))\n",
    "\n",
    "\n",
    "        #誤差\n",
    "        loss = functions.mean_squared_error(dd, y[:,t])\n",
    "        \n",
    "        delta_out[:,t] = functions.d_mean_squared_error(dd, y[:,t]) * (1-np.tanh(y[:,t]**2))\n",
    "        \n",
    "        all_loss += loss\n",
    "\n",
    "        out_bin[binary_dim - t - 1] = np.round(y[:,t])\n",
    "    \n",
    "    \n",
    "    for t in range(binary_dim)[::-1]:\n",
    "        X = np.array([a_bin[-t-1],b_bin[-t-1]]).reshape(1, -1)        \n",
    "\n",
    "        delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + np.dot(delta_out[:,t].T, W_out.T)) * functions.d_sigmoid(u[:,t+1])\n",
    "\n",
    "        # 勾配更新\n",
    "        W_out_grad += np.dot(z[:,t+1].reshape(-1,1), delta_out[:,t].reshape(-1,1))\n",
    "        W_grad += np.dot(z[:,t].reshape(-1,1), delta[:,t].reshape(1,-1))\n",
    "        W_in_grad += np.dot(X.T, delta[:,t].reshape(1,-1))\n",
    "    \n",
    "    # 勾配適用\n",
    "    W_in -= learning_rate * W_in_grad\n",
    "    W_out -= learning_rate * W_out_grad\n",
    "    W -= learning_rate * W_grad\n",
    "    \n",
    "    W_in_grad *= 0\n",
    "    W_out_grad *= 0\n",
    "    W_grad *= 0\n",
    "    \n",
    "\n",
    "    if(i % plot_interval == 0):\n",
    "        all_losses.append(all_loss)        \n",
    "        print(\"iters:\" + str(i))\n",
    "        print(\"Loss:\" + str(all_loss))\n",
    "        print(\"Pred:\" + str(out_bin))\n",
    "        print(\"True:\" + str(d_bin))\n",
    "        out_int = 0\n",
    "        for index,x in enumerate(reversed(out_bin)):\n",
    "            out_int += x * pow(2, index)\n",
    "        print(str(a_int) + \" + \" + str(b_int) + \" = \" + str(out_int))\n",
    "        print(\"------------\")\n",
    "\n",
    "lists = range(0, iters_num, plot_interval)\n",
    "plt.plot(lists, all_losses, label=\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
